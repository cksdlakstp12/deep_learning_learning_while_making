{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch로 YOLO구현하기.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM3kgYZtU6bxqWUOkvQNvJR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cksdlakstp12/deep_learning_study/blob/main/PyTorch%EB%A1%9C_YOLO%EA%B5%AC%ED%98%84%ED%95%98%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3mwZQLIrj18"
      },
      "source": [
        "from __future__ import division\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import os.path as osp\n",
        "import pickle as pkl\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "from urllib import request"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cX_TBKLrhr8"
      },
      "source": [
        "cfg 파일 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJeNCUkRDrTi",
        "outputId": "cddca068-4d51-4514-ed7f-1fd0ef291ea1"
      },
      "source": [
        "!git clone https://github.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'YOLO_v3_tutorial_from_scratch'...\n",
            "remote: Enumerating objects: 95, done.\u001b[K\n",
            "remote: Total 95 (delta 0), reused 0 (delta 0), pack-reused 95\u001b[K\n",
            "Unpacking objects: 100% (95/95), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YA-fSc-gEkyY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49113149-0641-44ae-fb35-d4314631f77b"
      },
      "source": [
        "cfg_url = \"https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\"\n",
        "dog_cycle_car_img_url = \"https://raw.githubusercontent.com/ayooshkathuria/pytorch-yolo-v3/master/dog-cycle-car.png\"\n",
        "yolo_weights_url = \"https://pjreddie.com/media/files/yolov3.weights\"\n",
        "\n",
        "saved_cfg_name = \"yolov3.cfg\"\n",
        "saved_img_name = \"dog-cycle-car.png\"\n",
        "saved_weights_name = \"yolov3.weights\"\n",
        "\n",
        "request.urlretrieve(cfg_url,saved_cfg_name)\n",
        "request.urlretrieve(dog_cycle_car_img_url,saved_img_name)\n",
        "request.urlretrieve(yolo_weights_url,saved_weights_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('yolov3.weights', <http.client.HTTPMessage at 0x7fc96d535b90>)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBisZ532rlw7"
      },
      "source": [
        "# darknet 계층 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pL9yDQ6r8el"
      },
      "source": [
        "def parse_cfg(cfgfile):\n",
        "  file = open(cfgfile, \"r\")\n",
        "  lines = file.read().split(\"\\n\")\n",
        "  lines = [x for x in lines if len(x) > 0]\n",
        "  lines = [x for x in lines if x[0] != \"#\"]\n",
        "  lines = [x.rstrip().lstrip() for x in lines]\n",
        "\n",
        "  block = {}\n",
        "  blocks = []\n",
        "\n",
        "  for line in lines:\n",
        "    if line[0] == \"[\":\n",
        "      if len(block) != 0:\n",
        "        blocks.append(block)\n",
        "        block = {}\n",
        "      block[\"type\"] = line[1:-1].rstrip()\n",
        "    else:\n",
        "      key, value = line.split(\"=\")\n",
        "      block[key.rstrip()] = value.lstrip()\n",
        "  blocks.append(block)\n",
        "\n",
        "  return blocks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrsevWgptlM3",
        "outputId": "53205599-eaa3-4542-f2b4-6cd2f6c9f3c4"
      },
      "source": [
        "blocks = parse_cfg(\"/content/yolov3.cfg\")\n",
        "print(blocks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'type': 'net', 'batch': '64', 'subdivisions': '16', 'width': '608', 'height': '608', 'channels': '3', 'momentum': '0.9', 'decay': '0.0005', 'angle': '0', 'saturation': '1.5', 'exposure': '1.5', 'hue': '.1', 'learning_rate': '0.001', 'burn_in': '1000', 'max_batches': '500200', 'policy': 'steps', 'steps': '400000,450000', 'scales': '.1,.1'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '32', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '64', 'size': '3', 'stride': '2', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '32', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '64', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'shortcut', 'from': '-3', 'activation': 'linear'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '3', 'stride': '2', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '64', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'shortcut', 'from': '-3', 'activation': 'linear'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '64', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'shortcut', 'from': '-3', 'activation': 'linear'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '2', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'shortcut', 'from': '-3', 'activation': 'linear'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'shortcut', 'from': '-3', 'activation': 'linear'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'shortcut', 'from': '-3', 'activation': 'linear'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'shortcut', 'from': '-3', 'activation': 'linear'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'shortcut', 'from': '-3', 'activation': 'linear'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'shortcut', 'from': '-3', 'activation': 'linear'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'shortcut', 'from': '-3', 'activation': 'linear'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'shortcut', 'from': '-3', 'activation': 'linear'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '2', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'shortcut', 'from': '-3', 'activation': 'linear'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'shortcut', 'from': '-3', 'activation': 'linear'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'shortcut', 'from': '-3', 'activation': 'linear'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'shortcut', 'from': '-3', 'activation': 'linear'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'shortcut', 'from': '-3', 'activation': 'linear'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'shortcut', 'from': '-3', 'activation': 'linear'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'shortcut', 'from': '-3', 'activation': 'linear'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'shortcut', 'from': '-3', 'activation': 'linear'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '1024', 'size': '3', 'stride': '2', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '1024', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'shortcut', 'from': '-3', 'activation': 'linear'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '1024', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'shortcut', 'from': '-3', 'activation': 'linear'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '1024', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'shortcut', 'from': '-3', 'activation': 'linear'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '1024', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'shortcut', 'from': '-3', 'activation': 'linear'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'size': '3', 'stride': '1', 'pad': '1', 'filters': '1024', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'size': '3', 'stride': '1', 'pad': '1', 'filters': '1024', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'size': '3', 'stride': '1', 'pad': '1', 'filters': '1024', 'activation': 'leaky'}, {'type': 'convolutional', 'size': '1', 'stride': '1', 'pad': '1', 'filters': '255', 'activation': 'linear'}, {'type': 'yolo', 'mask': '6,7,8', 'anchors': '10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326', 'classes': '80', 'num': '9', 'jitter': '.3', 'ignore_thresh': '.7', 'truth_thresh': '1', 'random': '1'}, {'type': 'route', 'layers': '-4'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'upsample', 'stride': '2'}, {'type': 'route', 'layers': '-1, 61'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'size': '3', 'stride': '1', 'pad': '1', 'filters': '512', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'size': '3', 'stride': '1', 'pad': '1', 'filters': '512', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'size': '3', 'stride': '1', 'pad': '1', 'filters': '512', 'activation': 'leaky'}, {'type': 'convolutional', 'size': '1', 'stride': '1', 'pad': '1', 'filters': '255', 'activation': 'linear'}, {'type': 'yolo', 'mask': '3,4,5', 'anchors': '10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326', 'classes': '80', 'num': '9', 'jitter': '.3', 'ignore_thresh': '.7', 'truth_thresh': '1', 'random': '1'}, {'type': 'route', 'layers': '-4'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'upsample', 'stride': '2'}, {'type': 'route', 'layers': '-1, 36'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'size': '3', 'stride': '1', 'pad': '1', 'filters': '256', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'size': '3', 'stride': '1', 'pad': '1', 'filters': '256', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'size': '3', 'stride': '1', 'pad': '1', 'filters': '256', 'activation': 'leaky'}, {'type': 'convolutional', 'size': '1', 'stride': '1', 'pad': '1', 'filters': '255', 'activation': 'linear'}, {'type': 'yolo', 'mask': '0,1,2', 'anchors': '10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326', 'classes': '80', 'num': '9', 'jitter': '.3', 'ignore_thresh': '.7', 'truth_thresh': '1', 'random': '1'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLRwA9997JBj"
      },
      "source": [
        "class EmptyLayer(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "class DetectionLayer(nn.Module):\n",
        "  def __init__(self, anchors):\n",
        "    super().__init__()\n",
        "    self.anchors = anchors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LN_uQG2xyZvK"
      },
      "source": [
        "def create_modules(blocks):\n",
        "  net_info = blocks[0]\n",
        "  module_list = nn.ModuleList()\n",
        "  prev_filters = 3\n",
        "  output_filters = []\n",
        "\n",
        "  for index, x in enumerate(blocks[1:]):\n",
        "    module = nn.Sequential()\n",
        "\n",
        "    if (x[\"type\"] == \"convolutional\"):\n",
        "      try:\n",
        "        batch_normalize = int(x[\"batch_normalize\"])\n",
        "        bias = False\n",
        "      except:\n",
        "        batch_normalize = 0\n",
        "        bias = True\n",
        "\n",
        "      filters = int(x[\"filters\"])\n",
        "      padding = int(x[\"pad\"])\n",
        "      kernel_size = int(x[\"size\"])\n",
        "      stride = int(x[\"stride\"])\n",
        "\n",
        "      if padding: pad = (kernel_size - 1) // 2\n",
        "      else: pad = 0\n",
        "\n",
        "      conv = nn.Conv2d(prev_filters, filters, kernel_size, stride, pad, bias=bias)\n",
        "      module.add_module(f\"conv_{index}\", conv)\n",
        "\n",
        "      if batch_normalize:\n",
        "        bn = nn.BatchNorm2d(filters)\n",
        "        module.add_module(f\"batch_norm_{index}\", bn)\n",
        "\n",
        "      if x[\"activation\"] == \"leaky\":\n",
        "        activn = nn.LeakyReLU(0.1, inplace=True)\n",
        "        module.add_module(f\"leaky_{index}\", activn)\n",
        "\n",
        "    elif (x[\"type\"] == \"upsample\"):\n",
        "      stride = int(x[\"stride\"])\n",
        "      upsample = nn.Upsample(scale_factor=stride, mode=\"bilinear\")\n",
        "      module.add_module(f\"upsample_{index}\", upsample)\n",
        "\n",
        "    elif (x[\"type\"] == \"route\"):\n",
        "      x[\"layers\"] = x[\"layers\"].split(\",\")\n",
        "\n",
        "      start = int(x[\"layers\"][0])\n",
        "\n",
        "      try: end = int(x[\"layers\"][1])\n",
        "      except: end = 0\n",
        "\n",
        "      if start > 0: start = start - index\n",
        "      if end > 0: end = end - index\n",
        "\n",
        "      route = EmptyLayer()\n",
        "      module.add_module(f\"route_{index}\", route)\n",
        "\n",
        "      if end < 0: filters = output_filters[index + start] + output_filters[index + end]\n",
        "      else: filters = output_filters[index + start]\n",
        "\n",
        "    elif x[\"type\"] == \"shortcut\":\n",
        "      shortcut = EmptyLayer()\n",
        "      module.add_module(f\"shortcut_{index}\", shortcut)\n",
        "\n",
        "    elif x[\"type\"] == \"yolo\":\n",
        "      mask = x[\"mask\"].split(\",\")\n",
        "      mask = [int(x) for x in mask]\n",
        "\n",
        "      anchors = x[\"anchors\"].split(\",\")\n",
        "      anchors = [int(a) for a in anchors]\n",
        "      anchors = [(anchors[i], anchors[i+1]) for i in range(0, len(anchors), 2)]\n",
        "      anchors = [anchors[i] for i in mask]\n",
        "\n",
        "      detection = DetectionLayer(anchors)\n",
        "      module.add_module(f\"Detection_{index}\", detection)\n",
        "\n",
        "    module_list.append(module)\n",
        "    prev_filters = filters\n",
        "    output_filters.append(filters)\n",
        "\n",
        "  return (net_info, module_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53dogZ5wzRKo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc3b1829-5bf9-47a0-cae6-048c4608e801"
      },
      "source": [
        "blocks = parse_cfg(\"/content/yolov3.cfg\")\n",
        "model = create_modules(blocks)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'type': 'net', 'batch': '64', 'subdivisions': '16', 'width': '608', 'height': '608', 'channels': '3', 'momentum': '0.9', 'decay': '0.0005', 'angle': '0', 'saturation': '1.5', 'exposure': '1.5', 'hue': '.1', 'learning_rate': '0.001', 'burn_in': '1000', 'max_batches': '500200', 'policy': 'steps', 'steps': '400000,450000', 'scales': '.1,.1'}, ModuleList(\n",
            "  (0): Sequential(\n",
            "    (conv_0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_0): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (1): Sequential(\n",
            "    (conv_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (2): Sequential(\n",
            "    (conv_2): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (3): Sequential(\n",
            "    (conv_3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_3): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (4): Sequential(\n",
            "    (shortcut_4): EmptyLayer()\n",
            "  )\n",
            "  (5): Sequential(\n",
            "    (conv_5): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (batch_norm_5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (6): Sequential(\n",
            "    (conv_6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_6): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (7): Sequential(\n",
            "    (conv_7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_7): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (8): Sequential(\n",
            "    (shortcut_8): EmptyLayer()\n",
            "  )\n",
            "  (9): Sequential(\n",
            "    (conv_9): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_9): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (10): Sequential(\n",
            "    (conv_10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_10): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (11): Sequential(\n",
            "    (shortcut_11): EmptyLayer()\n",
            "  )\n",
            "  (12): Sequential(\n",
            "    (conv_12): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (batch_norm_12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_12): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (13): Sequential(\n",
            "    (conv_13): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_13): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (14): Sequential(\n",
            "    (conv_14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_14): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (15): Sequential(\n",
            "    (shortcut_15): EmptyLayer()\n",
            "  )\n",
            "  (16): Sequential(\n",
            "    (conv_16): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_16): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (17): Sequential(\n",
            "    (conv_17): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_17): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_17): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (18): Sequential(\n",
            "    (shortcut_18): EmptyLayer()\n",
            "  )\n",
            "  (19): Sequential(\n",
            "    (conv_19): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_19): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (20): Sequential(\n",
            "    (conv_20): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_20): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_20): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (21): Sequential(\n",
            "    (shortcut_21): EmptyLayer()\n",
            "  )\n",
            "  (22): Sequential(\n",
            "    (conv_22): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_22): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (23): Sequential(\n",
            "    (conv_23): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_23): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_23): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (24): Sequential(\n",
            "    (shortcut_24): EmptyLayer()\n",
            "  )\n",
            "  (25): Sequential(\n",
            "    (conv_25): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_25): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_25): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (26): Sequential(\n",
            "    (conv_26): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_26): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_26): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (27): Sequential(\n",
            "    (shortcut_27): EmptyLayer()\n",
            "  )\n",
            "  (28): Sequential(\n",
            "    (conv_28): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_28): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_28): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (29): Sequential(\n",
            "    (conv_29): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_29): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_29): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (30): Sequential(\n",
            "    (shortcut_30): EmptyLayer()\n",
            "  )\n",
            "  (31): Sequential(\n",
            "    (conv_31): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_31): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_31): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (32): Sequential(\n",
            "    (conv_32): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_32): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_32): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (33): Sequential(\n",
            "    (shortcut_33): EmptyLayer()\n",
            "  )\n",
            "  (34): Sequential(\n",
            "    (conv_34): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_34): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_34): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (35): Sequential(\n",
            "    (conv_35): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_35): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_35): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (36): Sequential(\n",
            "    (shortcut_36): EmptyLayer()\n",
            "  )\n",
            "  (37): Sequential(\n",
            "    (conv_37): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (batch_norm_37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_37): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (38): Sequential(\n",
            "    (conv_38): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_38): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_38): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (39): Sequential(\n",
            "    (conv_39): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_39): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_39): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (40): Sequential(\n",
            "    (shortcut_40): EmptyLayer()\n",
            "  )\n",
            "  (41): Sequential(\n",
            "    (conv_41): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_41): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_41): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (42): Sequential(\n",
            "    (conv_42): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_42): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_42): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (43): Sequential(\n",
            "    (shortcut_43): EmptyLayer()\n",
            "  )\n",
            "  (44): Sequential(\n",
            "    (conv_44): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_44): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_44): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (45): Sequential(\n",
            "    (conv_45): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_45): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_45): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (46): Sequential(\n",
            "    (shortcut_46): EmptyLayer()\n",
            "  )\n",
            "  (47): Sequential(\n",
            "    (conv_47): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_47): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_47): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (48): Sequential(\n",
            "    (conv_48): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_48): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_48): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (49): Sequential(\n",
            "    (shortcut_49): EmptyLayer()\n",
            "  )\n",
            "  (50): Sequential(\n",
            "    (conv_50): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_50): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_50): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (51): Sequential(\n",
            "    (conv_51): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_51): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_51): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (52): Sequential(\n",
            "    (shortcut_52): EmptyLayer()\n",
            "  )\n",
            "  (53): Sequential(\n",
            "    (conv_53): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_53): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_53): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (54): Sequential(\n",
            "    (conv_54): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_54): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_54): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (55): Sequential(\n",
            "    (shortcut_55): EmptyLayer()\n",
            "  )\n",
            "  (56): Sequential(\n",
            "    (conv_56): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_56): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_56): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (57): Sequential(\n",
            "    (conv_57): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_57): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_57): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (58): Sequential(\n",
            "    (shortcut_58): EmptyLayer()\n",
            "  )\n",
            "  (59): Sequential(\n",
            "    (conv_59): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_59): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_59): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (60): Sequential(\n",
            "    (conv_60): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_60): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_60): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (61): Sequential(\n",
            "    (shortcut_61): EmptyLayer()\n",
            "  )\n",
            "  (62): Sequential(\n",
            "    (conv_62): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (batch_norm_62): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_62): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (63): Sequential(\n",
            "    (conv_63): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_63): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_63): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (64): Sequential(\n",
            "    (conv_64): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_64): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_64): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (65): Sequential(\n",
            "    (shortcut_65): EmptyLayer()\n",
            "  )\n",
            "  (66): Sequential(\n",
            "    (conv_66): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_66): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_66): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (67): Sequential(\n",
            "    (conv_67): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_67): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_67): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (68): Sequential(\n",
            "    (shortcut_68): EmptyLayer()\n",
            "  )\n",
            "  (69): Sequential(\n",
            "    (conv_69): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_69): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_69): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (70): Sequential(\n",
            "    (conv_70): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_70): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_70): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (71): Sequential(\n",
            "    (shortcut_71): EmptyLayer()\n",
            "  )\n",
            "  (72): Sequential(\n",
            "    (conv_72): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_72): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_72): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (73): Sequential(\n",
            "    (conv_73): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_73): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_73): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (74): Sequential(\n",
            "    (shortcut_74): EmptyLayer()\n",
            "  )\n",
            "  (75): Sequential(\n",
            "    (conv_75): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_75): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_75): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (76): Sequential(\n",
            "    (conv_76): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_76): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_76): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (77): Sequential(\n",
            "    (conv_77): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_77): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_77): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (78): Sequential(\n",
            "    (conv_78): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_78): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_78): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (79): Sequential(\n",
            "    (conv_79): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_79): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_79): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (80): Sequential(\n",
            "    (conv_80): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_80): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_80): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (81): Sequential(\n",
            "    (conv_81): Conv2d(1024, 255, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (82): Sequential(\n",
            "    (Detection_82): DetectionLayer()\n",
            "  )\n",
            "  (83): Sequential(\n",
            "    (route_83): EmptyLayer()\n",
            "  )\n",
            "  (84): Sequential(\n",
            "    (conv_84): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_84): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_84): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (85): Sequential(\n",
            "    (upsample_85): Upsample(scale_factor=2.0, mode=bilinear)\n",
            "  )\n",
            "  (86): Sequential(\n",
            "    (route_86): EmptyLayer()\n",
            "  )\n",
            "  (87): Sequential(\n",
            "    (conv_87): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_87): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_87): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (88): Sequential(\n",
            "    (conv_88): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_88): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_88): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (89): Sequential(\n",
            "    (conv_89): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_89): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_89): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (90): Sequential(\n",
            "    (conv_90): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_90): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_90): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (91): Sequential(\n",
            "    (conv_91): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_91): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_91): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (92): Sequential(\n",
            "    (conv_92): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_92): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_92): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (93): Sequential(\n",
            "    (conv_93): Conv2d(512, 255, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (94): Sequential(\n",
            "    (Detection_94): DetectionLayer()\n",
            "  )\n",
            "  (95): Sequential(\n",
            "    (route_95): EmptyLayer()\n",
            "  )\n",
            "  (96): Sequential(\n",
            "    (conv_96): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_96): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_96): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (97): Sequential(\n",
            "    (upsample_97): Upsample(scale_factor=2.0, mode=bilinear)\n",
            "  )\n",
            "  (98): Sequential(\n",
            "    (route_98): EmptyLayer()\n",
            "  )\n",
            "  (99): Sequential(\n",
            "    (conv_99): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_99): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_99): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (100): Sequential(\n",
            "    (conv_100): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_100): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_100): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (101): Sequential(\n",
            "    (conv_101): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_101): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_101): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (102): Sequential(\n",
            "    (conv_102): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_102): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_102): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (103): Sequential(\n",
            "    (conv_103): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_103): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_103): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (104): Sequential(\n",
            "    (conv_104): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_104): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_104): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "  )\n",
            "  (105): Sequential(\n",
            "    (conv_105): Conv2d(256, 255, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (106): Sequential(\n",
            "    (Detection_106): DetectionLayer()\n",
            "  )\n",
            "))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySqElDWHOZrO"
      },
      "source": [
        "# YOLO 신경망 구조 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcZ2x9g76PE_"
      },
      "source": [
        "class Darknet(nn.Module):\n",
        "  def __init__(self, cfgfile):\n",
        "    super(Darknet, self).__init__()\n",
        "    self.blocks = parse_cfg(cfgfile)\n",
        "    self.net_info, self.module_list = create_modules(self.blocks)\n",
        "\n",
        "  def forward(self, x, CUDA):\n",
        "    modules = self.blocks[1:]\n",
        "    outputs = {}\n",
        "\n",
        "    write = 0\n",
        "    for i, module in enumerate(modules):\n",
        "      module_type = (module[\"type\"])\n",
        "      \n",
        "      if module_type == \"convolutional\" or module_type == \"upsample\":\n",
        "        x = self.module_list[i](x)\n",
        "      \n",
        "      elif module_type == \"route\":\n",
        "        layers = module[\"layers\"]\n",
        "        layers = [int(a) for a in layers]\n",
        "\n",
        "        if (layers[0]) > 0:\n",
        "          layers[0] = layers[0] - i\n",
        "\n",
        "        if len(layers) == 1:\n",
        "          x = outputs[i + (layers[0])]\n",
        "\n",
        "        else:\n",
        "          if (layers[1]) > 0:\n",
        "            layers[1] = layers[1] - i\n",
        "\n",
        "          map1 = outputs[i + layers[0]]\n",
        "          map2 = outputs[i + layers[1]]\n",
        "\n",
        "          x = torch.cat((map1, map2), 1)\n",
        "      \n",
        "      elif module_type == \"shortcut\":\n",
        "        from_ = int(module[\"from\"])\n",
        "        x = outputs[i-1] + outputs[i+from_]\n",
        "\n",
        "      elif module_type == \"yolo\":\n",
        "        anchors = self.module_list[i][0].anchors\n",
        "        inp_dim = int(self.net_info[\"height\"])\n",
        "        num_classes = int(module[\"classes\"])\n",
        "        \n",
        "        x = x.data\n",
        "        x = predict_transform(x, inp_dim, anchors, num_classes, CUDA)\n",
        "        if not write:\n",
        "          detections = x\n",
        "          write = 1\n",
        "        else:\n",
        "          detections = torch.cat((detections, x), 1)\n",
        "        \n",
        "      outputs[i] = x\n",
        "    \n",
        "    return detections\n",
        "\n",
        "  def load_weights(self, weightfile):\n",
        "    with open(weightfile, \"rb\") as fp:\n",
        "      header = np.fromfile(fp, dtype = np.int32, count=5)\n",
        "      self.header = torch.from_numpy(header)\n",
        "      self.seen = self.header[3]\n",
        "\n",
        "      weights = np.fromfile(fp, dtype=np.float32)\n",
        "\n",
        "      ptr = 0\n",
        "      for i in range(len(self.module_list)):\n",
        "        module_type = self.blocks[i+1][\"type\"]\n",
        "\n",
        "        if module_type == \"convolutional\":\n",
        "          model = self.module_list[i]\n",
        "          try:\n",
        "            batch_normalize = int(self.blocks[i+1][\"batch_normalize\"])\n",
        "          except:\n",
        "            batch_normalize = 0\n",
        "\n",
        "          conv = model[0]\n",
        "\n",
        "          if batch_normalize:\n",
        "            bn = model[1]\n",
        "\n",
        "            num_bn_biases = bn.bias.numel()\n",
        "\n",
        "            bn_biases = torch.from_numpy(weights[ptr:ptr+num_bn_biases])\n",
        "            ptr += num_bn_biases\n",
        "\n",
        "            bn_weights = torch.from_numpy(weights[ptr:ptr+num_bn_biases])\n",
        "            ptr += num_bn_biases\n",
        "\n",
        "            bn_running_mean = torch.from_numpy(weights[ptr:ptr+num_bn_biases])\n",
        "            ptr += num_bn_biases\n",
        "\n",
        "            bn_running_var = torch.from_numpy(weights[ptr:ptr+num_bn_biases])\n",
        "            ptr += num_bn_biases\n",
        "\n",
        "            bn_biases = bn_biases.view_as(bn.bias.data)\n",
        "            bn_weights = bn_weights.view_as(bn.weight.data)\n",
        "            bn_running_mean = bn_running_mean.view_as(bn.running_mean)\n",
        "            bn_running_var = bn_running_var.view_as(bn.running_var)\n",
        "\n",
        "            bn.bias.data.copy_(bn_biases)\n",
        "            bn.weight.data.copy_(bn_weights)\n",
        "            bn.running_mean.copy_(bn_running_mean)\n",
        "            bn.running_var.copy_(bn_running_var)\n",
        "          \n",
        "          else:\n",
        "            num_biases = conv.bias.numel()\n",
        "\n",
        "            conv_biases = torch.from_numpy(weights[ptr:ptr+num_biases])\n",
        "            ptr = ptr + num_biases\n",
        "\n",
        "            conv_biases = conv_biases.view_as(conv.bias.data)\n",
        "            conv.bias.data.copy_(conv_biases)\n",
        "\n",
        "          num_weights = conv.weight.numel()\n",
        "          \n",
        "          conv_weights = torch.from_numpy(weights[ptr:ptr+num_weights])\n",
        "          ptr = ptr + num_weights\n",
        "\n",
        "          conv_weights = conv_weights.view_as(conv.weight.data)\n",
        "          conv.weight.data.copy_(conv_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vd2TdUdsNGWS"
      },
      "source": [
        "def predict_transform(prediction, inp_dim, anchors, num_classes, CUDA=True):\n",
        "  batch_size = prediction.size(0)\n",
        "  stride = inp_dim / prediction.size(2)\n",
        "  grid_size = int(inp_dim // stride)\n",
        "  stride = int(stride)\n",
        "  bbox_attrs = 5 + num_classes\n",
        "  num_anchors = len(anchors)\n",
        "  \n",
        "  prediction = prediction.view(batch_size, bbox_attrs * num_anchors, grid_size * grid_size)\n",
        "  prediction = prediction.transpose(1,2).contiguous()\n",
        "  prediction = prediction.view(batch_size, grid_size * grid_size * num_anchors, bbox_attrs)\n",
        "\n",
        "  anchors = [(a[0]/stride, a[1]/stride) for a in anchors]\n",
        "\n",
        "  prediction[:,:,0] = torch.sigmoid(prediction[:,:,0])\n",
        "  prediction[:,:,1] = torch.sigmoid(prediction[:,:,1])\n",
        "  prediction[:,:,4] = torch.sigmoid(prediction[:,:,4])\n",
        "\n",
        "  grid = np.arange(grid_size)\n",
        "  a, b = np.meshgrid(grid, grid)\n",
        "  x_offset = torch.FloatTensor(a).view(-1, 1)\n",
        "  y_offset = torch.FloatTensor(b).view(-1, 1)\n",
        "\n",
        "  if CUDA:\n",
        "    x_offset = x_offset.cuda()\n",
        "    y_offset = y_offset.cuda()\n",
        "\n",
        "  x_y_offset = torch.cat((x_offset, y_offset), 1).repeat(1, num_anchors).view(-1, 2).unsqueeze(0)\n",
        "  prediction[:,:,:2] += x_y_offset\n",
        "\n",
        "  anchors = torch.FloatTensor(anchors)\n",
        "\n",
        "  if CUDA:\n",
        "    anchors = anchors.cuda()\n",
        "  \n",
        "  anchors = anchors.repeat(grid_size * grid_size, 1).unsqueeze(0)\n",
        "  prediction[:,:,2:4] = torch.exp(prediction[:,:,2:4]) * anchors\n",
        "  prediction[:,:,5:5 + num_classes] = torch.sigmoid((prediction[:,:,5:5+num_classes]))\n",
        "  prediction[:,:,:4] *= stride\n",
        "\n",
        "  return prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mf-2YBlTDrYG",
        "outputId": "e685176d-1bd8-4387-ee4f-4dd4fc6dd179"
      },
      "source": [
        "# 순전파 테스트\n",
        "\n",
        "def get_test_input():\n",
        "  img = cv2.imread(\"dog-cycle-car.png\")\n",
        "  img = cv2.resize(img, (416, 416))\n",
        "  img_ = img[:,:,::-1].transpose((2,0,1))\n",
        "  img_ = img_[np.newaxis,:,:,:]/255.0\n",
        "  img_ = torch.from_numpy(img_).float()\n",
        "  img_ = Variable(img_)\n",
        "  return img_\n",
        "\n",
        "model = Darknet(\"yolov3.cfg\")\n",
        "inp = get_test_input()\n",
        "pred = model(inp, torch.cuda.is_available())\n",
        "print(pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3613: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[2.4213e+01, 2.6042e+01, 1.0305e+02,  ..., 4.8836e-01,\n",
            "          4.7237e-01, 4.9009e-01],\n",
            "         [2.6077e+01, 2.4159e+01, 1.2255e+02,  ..., 4.5722e-01,\n",
            "          5.5009e-01, 5.5051e-01],\n",
            "         [2.0923e+01, 2.8121e+01, 3.6447e+02,  ..., 4.3059e-01,\n",
            "          3.5980e-01, 4.7601e-01],\n",
            "         ...,\n",
            "         [5.6651e+02, 5.6618e+02, 4.9607e+00,  ..., 5.2353e-01,\n",
            "          4.4016e-01, 5.6673e-01],\n",
            "         [5.6639e+02, 5.6696e+02, 2.1043e+01,  ..., 5.4348e-01,\n",
            "          5.0600e-01, 4.8549e-01],\n",
            "         [5.6597e+02, 5.6600e+02, 3.8086e+01,  ..., 5.3822e-01,\n",
            "          5.2525e-01, 4.3345e-01]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxiCi6duXpDH"
      },
      "source": [
        "# load_weights 테스트\n",
        "\n",
        "model = Darknet(\"yolov3.cfg\")\n",
        "model.load_weights(\"yolov3.weights\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeGYmeQwDrQ0"
      },
      "source": [
        "def write_results(prediction, confidence, num_classes, nms_conf = 0.4):\n",
        "  conf_mask = (prediction[:,:,4] > confidence).float().unsqueeze(2)\n",
        "  prediction = prediction * conf_mask\n",
        "\n",
        "  box_corner = prediction.new(prediction.shape)\n",
        "  box_corner[:,:,0] = (prediction[:,:,0] - prediction[:,:,2]/2)\n",
        "  box_corner[:,:,1] = (prediction[:,:,1] - prediction[:,:,3]/2)\n",
        "  box_corner[:,:,2] = (prediction[:,:,0] + prediction[:,:,2]/2)\n",
        "  box_corner[:,:,3] = (prediction[:,:,1] + prediction[:,:,3]/2)\n",
        "  prediction[:,:,:4] = box_corner[:,:,:4]\n",
        "\n",
        "  batch_size = prediction.size(0)\n",
        "  write = 0\n",
        "  for ind in range(batch_size):\n",
        "    image_pred = prediction[ind]\n",
        "\n",
        "    # max_conf, max_conf_index = torch.max(image_pred[:,5:5+num_classes], 1)\n",
        "    max_conf, max_conf_index = map(lambda x: x.float().unsqueeze(1), torch.max(image_pred[:,5:5+num_classes], 1))\n",
        "    # max_conf = max_conf.float().unsqueeze(1)\n",
        "    # max_conf_index = max_conf_index.float().unsqueeze(1)\n",
        "    seq = (image_pred[:,:5], max_conf, max_conf_index)\n",
        "    image_pred = torch.cat(seq, 1)\n",
        "\n",
        "    non_zero_ind = (torch.nonzero(image_pred[:, 4]))\n",
        "    try: image_pred_ = image_pred[non_zero_ind.squeeze(), :].view(-1, 7)\n",
        "    except: continue\n",
        "\n",
        "    if image_pred_.shape[0] == 0: continue\n",
        "\n",
        "    img_classes = unique(image_pred_[:, -1])\n",
        "\n",
        "    for cls in img_classes:\n",
        "      cls_mask = image_pred_ * (image_pred_[:, -1] == cls).float().unsqueeze(1)\n",
        "      class_mask_ind = torch.nonzero(cls_mask[:,-2]).squeeze()\n",
        "      image_pred_class = image_pred_[class_mask_ind].view(-1, 7)\n",
        "\n",
        "      conf_sort_index = torch.sort(image_pred_class[:,4], descending=True)[1]\n",
        "      image_pred_class = image_pred_class[conf_sort_index]\n",
        "      idx = image_pred_class.size(0)\n",
        "\n",
        "      for i in range(idx):\n",
        "        try:\n",
        "          ious = bbox_iou(image_pred_class[i].unsqueeze(0), image_pred_class[i+1:])\n",
        "        except ValueError: break\n",
        "        except IndexError: break\n",
        "\n",
        "        iou_mask = (ious < nms_conf).float().unsqueeze(1)\n",
        "        image_pred_class[i+1:] *= iou_mask\n",
        "\n",
        "        non_zero_ind = torch.nonzero(image_pred_class[:,4]).squeeze()\n",
        "        image_pred_class = image_pred_class[non_zero_ind].view(-1, 7)\n",
        "\n",
        "      batch_ind = image_pred_class.new(image_pred_class.size(0), 1).fill_(ind)\n",
        "      seq = batch_ind, image_pred_class\n",
        "\n",
        "      if not write:\n",
        "        output = torch.cat(seq, 1)\n",
        "        write = True\n",
        "      else:\n",
        "        out = torch.cat(seq, 1)\n",
        "        output = torch.cat((output, out))\n",
        "    \n",
        "  try: return output\n",
        "  except: return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyV-jUML4so1"
      },
      "source": [
        "def unique(tensor):\n",
        "  tensor_np = tensor.cpu().numpy()\n",
        "  unique_np = np.unique(tensor_np)\n",
        "  unique_tensor = torch.from_numpy(unique_np)\n",
        "\n",
        "  tensor_res = tensor.new(unique_tensor.shape)\n",
        "  tensor_res.copy_(unique_tensor)\n",
        "  return tensor_res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCCt_V1M4smt"
      },
      "source": [
        "def bbox_iou(box1, box2):\n",
        "  b1_x1, b1_y1, b1_x2, b1_y2 = box1[:,0], box1[:,1], box1[:,2], box1[:,3]\n",
        "  b2_x1, b2_y1, b2_x2, b2_y2 = box2[:,0], box2[:,1], box2[:,2], box2[:,3]\n",
        "\n",
        "  inter_rect_x1 = torch.max(b1_x1, b2_x1)\n",
        "  inter_rect_y1 = torch.max(b1_y1, b2_y1)\n",
        "  inter_rect_x2 = torch.min(b1_x2, b2_x2)\n",
        "  inter_rect_y2 = torch.min(b1_y2, b2_y2)\n",
        "\n",
        "  inter_area = torch.clamp(inter_rect_x2 - inter_rect_x1 + 1, min=0) * \\\n",
        "                torch.clamp(inter_rect_y2 - inter_rect_y1 + 1, min=0)\n",
        "\n",
        "  b1_area = (b1_x2 - b1_x1 + 1)*(b1_y2 - b1_y1 + 1)\n",
        "  b2_area = (b2_x2 - b2_x1 + 1)*(b2_y2 - b2_y1 + 1)\n",
        "\n",
        "  iou = inter_area / (b1_area + b2_area - inter_area)\n",
        "\n",
        "  return iou"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3SWXe0vM5jt"
      },
      "source": [
        "run after converting ipynb to py\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmy846KJM7tb"
      },
      "source": [
        "def arg_parse():\n",
        "  parser = argparse.ArgumentParser(description=\"YOLO v3 Detection Module\")\n",
        "  parser.add_argument(\"--images\", dest=\"images\", \n",
        "                     help=\"Image / Directory containing images to perform detection upon\",\n",
        "                     default = \"imgs\", type = str)\n",
        "  parser.add_argument(\"--det\", dest = \"det\", \n",
        "                      help = \"Image / Directory to store detections to\",\n",
        "                      default = \"det\", type = str)\n",
        "  parser.add_argument(\"--bs\", dest = \"bs\", help = \"Batch size\", default = 1)\n",
        "  parser.add_argument(\"--confidence\", dest = \"confidence\", \n",
        "                      help=\"Object Confidence to filter predictions\", default = 0.5)\n",
        "  parser.add_argument(\"--nms_thresh\", dest = \"nms_thresh\", help = \"NMS Threshhold\", default = 0.4)\n",
        "  parser.add_argument(\"--n_cls\", dest = \"num_classes\", help = \"Num of Classes\", default = 80)\n",
        "  parser.add_argument(\"--coco\", dest = \"classes\", help = \"coco data file\",\n",
        "                      default = \"data/coco.names\", type = str)\n",
        "  parser.add_argument(\"--cfg\", dest = \"cfgfile\", help = \"config file\",\n",
        "                      default = \"cfg/yolov3.cfg\", type = str)\n",
        "  parser.add_argument(\"--weights\", dest = \"weightsfile\", help = \"weightsfile\",\n",
        "                      default = \"yolov3.weights\", type = str)\n",
        "  parser.add_argument(\"--reso\", dest = \"reso\",\n",
        "                      help = \"Input resolution of the network. Increase to increase accuracy. Decrease to increase speed\",\n",
        "                      default = \"416\", type = str)\n",
        "  return parser.parse_args()\n",
        "\n",
        "\n",
        "def load_classes(namesfile):\n",
        "  fp = open(namesfile, \"r\")\n",
        "  names = fp.read().split(\"\\n\")[:-1]\n",
        "  fp.close()\n",
        "  return names\n",
        "\n",
        "\n",
        "def letterbox_image(img, inp_dim):\n",
        "  img_w, img_h = img.shape[1], img.shape[0]\n",
        "  w, h = inp_dim\n",
        "  new_w = int(img_w * min(w/img_w, h/img_h))\n",
        "  new_h = int(img_h * min(w/img_w, h/img_h))\n",
        "  resized_image = cv2.resize(img, (new_w, new_h), interpolation = cv2.INTER_CUBIC)\n",
        "\n",
        "  canvas = np.full((inp_dim[1], inp_dim[0], 3), 128)\n",
        "\n",
        "  canvas[(h-new_h)//2:(h-new_h)//2 + new_h, (w-new_w)//2:(w-new_w)//2 + new_w, :] = resized_image\n",
        "\n",
        "  return canvas\n",
        "\n",
        "\n",
        "def prep_image(img, inp_dim):\n",
        "  img = cv2.resize(img, (inp_dim, inp_dim))\n",
        "  img = img[:,:,::-1].transpose((2,0,1)).copy()\n",
        "  img = torch.from_numpy(img).float().div(255.0).unsqueeze(0)\n",
        "  return img\n",
        "\n",
        "\n",
        "def write(x, results, color):\n",
        "  c1 = tuple(x[1:3].int())\n",
        "  c2 = tuple(x[3:5].int())\n",
        "  img = results[int(x[0])]\n",
        "  cls = int(x[-1])\n",
        "  label = f\"{classes[cls]}\"\n",
        "  cv2.retangle(img, c1, c2, color, 1)\n",
        "  t_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_PLAIN, 1, 1)[0]\n",
        "  c2 = c1[0] + t_size[0] + 3, c1[1] + t_size[1] + 4\n",
        "  cv2.rectangle(img, c1, c2, color, -1)\n",
        "  cv2.putText(img, label, (c1[0], c1[1] + t_size[1] + 4), cv2.FONT_HERSHEY_PLAIN, 1, [255,255,255], 1)\n",
        "  return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RI346sDn_lE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "03afd8ab-1ed2-4318-c4d1-91efa26c01a5"
      },
      "source": [
        "import argparse\n",
        "\n",
        "args = arg_parse()\n",
        "images = args.images\n",
        "batch_size = int(args.bs)\n",
        "confidence = float(args.confidence)\n",
        "nms_thesh = float(args.nms_thresh)\n",
        "num_classes = int(args.num_classes)\n",
        "start = 0\n",
        "classes = load_classes(args.classes)\n",
        "CUDA = torch.cuda.is_available()\n",
        "\n",
        "print(\"Loading network.....\", end=\"\")\n",
        "model = Darknet(args.cfgfile)\n",
        "model.load_wegihts(args.weightsfile)\n",
        "print(\"Network successfully loaded!\")\n",
        "print(f\"Network predict using {'cuda' if CUDA else 'cpu'}\")\n",
        "\n",
        "model.net_info[\"height\"] = args.reso\n",
        "inp_dim = int(model.net_info[\"height\"])\n",
        "assert inp_dim % 32 == 0\n",
        "assert inp_dim > 32\n",
        "\n",
        "if CUDA: model.cuda()\n",
        "model.eval()\n",
        "\n",
        "read_dir = time.time()\n",
        "\n",
        "try:\n",
        "  imlist = [osp.join(osp.realpath(\".\"), images, img) for img in os.listdir(images)]\n",
        "except NotADirectoryError:\n",
        "  imlist = []\n",
        "  imlist.append(osp.join(osp.realpath(\".\"), images))\n",
        "except FileNotFoundError:\n",
        "  print(f\"No file or directory with the name {images}\")\n",
        "  exit()\n",
        "\n",
        "if not os.path.exists(args.det):\n",
        "  os.makedirs(args.det)\n",
        "\n",
        "load_batch = time.time()\n",
        "loaded_ims = [cv2.imread(x) for x in imlist]\n",
        "\n",
        "im_batches = list(map(prep_image, loaded_ims, [inp_dim for x in range(len(imlist))]))\n",
        "\n",
        "im_dim_list = [(x.shape[1], x.shape[0]) for x in loaded_ims]\n",
        "im_dim_list = torch.FloatTensor(im_dim_list).repeat(1, 2)\n",
        "\n",
        "if CUDA: im_dim_list = im_dim_list.cuda()\n",
        "\n",
        "leftover = 0\n",
        "if (len(im_dim_list) % batch_size):\n",
        "  leftover = 1\n",
        "\n",
        "if batch_size != 1:\n",
        "  num_batches = len(imlist) // batch_size + leftover\n",
        "  im_batches = [torch.cat((im_batches[i*batch_size : min((i + 1)*batch_size,\n",
        "                  len(im_batches))])) for i in range(num_batches)]\n",
        "\n",
        "write = 0\n",
        "start_det_loop = time.time()\n",
        "for i, batch in enumerate(im_batches):\n",
        "  start = time.time()\n",
        "  if CUDA: batch = batch.cuda()\n",
        "\n",
        "  prediction = model(Variable(batch, volatile = True), CUDA)\n",
        "\n",
        "  prediction = write_results(prediction, confidence, num_classes, nms_conf = nms_thresh)\n",
        "\n",
        "  end = time.time()\n",
        "\n",
        "  if type(prediction) == int:\n",
        "\n",
        "    for im_num, image in enumerate(imlist[i*batch_size: min((i+1)*batch_size, len(imlist))]):\n",
        "      im_id = i*batch_size + im_num\n",
        "      print(\"{0:20s} prdicted in {1:6.3f} seconds\".format(image.split(\"/\")[-1], (end-start)/batch_size))\n",
        "      print(\"{0:20s} {1:s}\".format(\"Objects Detected:\", \"\"))\n",
        "      print(\"-\"*50)\n",
        "\n",
        "    continue\n",
        "  \n",
        "  prediction[:, 0] += i*batch_size\n",
        "\n",
        "  if not write:\n",
        "    output = prediction\n",
        "    write = 1\n",
        "  else:\n",
        "    output = torch.cat((output, prediction))\n",
        "\n",
        "  for im_num, image in enumerate(imlist[i*batch_size: min((i+1)*batch_size, len(imlist))]):\n",
        "    im_id = i*batch_size + im_num\n",
        "    objs = [classes[int(x[-1])] for x in output if int(x[0]) == im_id]\n",
        "    print(\"{0:20s} predicted in {1:6.3f} seconds\".format(image.split(\"/\")[-1], (end-start)/batch_size))\n",
        "    print(\"{0:20s} {1:s}\".format(\"Objects Detected:\",\" \".join(objs)))\n",
        "    print(\"-\"*50)\n",
        "\n",
        "  if CUDA: torch.cuda.synchronize()\n",
        "\n",
        "try: output\n",
        "except NameError:\n",
        "  print(\"No detections were made\")\n",
        "  exit()\n",
        "\n",
        "im_dim_list = torch.index_select(im_dim_list, 0, output[:, 0].long())\n",
        "scaling_factor = torch.min(inp_dim/im_dim_list, 1)[0].view(-1, 1)\n",
        "\n",
        "output[:,[1, 3]] -= (inp_dim - scaling_factor*im_dim_list[:, 0].view(-1, 1))/2\n",
        "output[:,[2, 4]] -= (inp_dim - scaling_factor*im_dim_list[:, 1].view(-1, 1))/2\n",
        "\n",
        "output[:, 1:5] /= scaling_factor\n",
        "\n",
        "for i in range(output.shape[0]):\n",
        "  output[i, [1, 3]] = torch.clamp(output[i, [1, 3]], 0.0, im_dim_list[i, 0])\n",
        "  output[i, [2, 4]] = torch.clamp(output[i, [2, 4]], 0.0, im_dim_list[i, 1])\n",
        "\n",
        "class_load = time.time()\n",
        "colors = pkl.load(open(\"/content/YOLO_v3_tutorial_from_scratch/pallete\", \"rb\"))\n",
        "\n",
        "draw = time.time()\n",
        "\n",
        "list(map(lambda x: write(x, loaded_ims, colors), output))\n",
        "\n",
        "det_names = pd.Series(imlist).apply(lambda x: f\"{args.det}/det_{x.split('/')[-1]}\")\n",
        "\n",
        "list(map(cv2.imwrite, det_names, loaded_ims))\n",
        "end = time.time()\n",
        "\n",
        "print(\"SUMMARY\")\n",
        "print(\"-\"*50)\n",
        "print(\"{:25s}: {}\".format(\"Task\", \"Time Taken (in seconds)\"))\n",
        "print()\n",
        "print(\"{:25s}: {:2.3f}\".format(\"Reading addresses\", load_batch - read_dir))\n",
        "print(\"{:25s}: {:2.3f}\".format(\"Loading batch\", start_det_loop - load_batch))\n",
        "print(\"{:25s}: {:2.3f}\".format(\"Detection (\" + str(len(imlist)) + \" images\", output_recast - start_det_loop))\n",
        "print(\"{:25s}: {:2.3f}\".format(\"Output Processing\", class_load - output_recast))\n",
        "print(\"{:25s}: {:2.3f}\".format(\"Drawing Boxes\", end - draw))\n",
        "print(\"{:25s}: {:2.3f}\".format(\"Average time_per_img\", (end - load_batch)/len(imlist)))\n",
        "print(\"-\"*50)\n",
        "\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: ipykernel_launcher.py [-h] [--images IMAGES] [--det DET] [--bs BS]\n",
            "                             [--confidence CONFIDENCE]\n",
            "                             [--nms_thresh NMS_THRESH] [--n_cls NUM_CLASSES]\n",
            "                             [--coco CLASSES] [--cfg CFGFILE]\n",
            "                             [--weights WEIGHTSFILE] [--reso RESO]\n",
            "ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-bdd35cc8-5401-4d44-af90-b5fc4bf037bd.json\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIujyxZdMOKm"
      },
      "source": [
        "https://github.com/WongKinYiu/ScaledYOLOv4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7RZEsE5CW7n"
      },
      "source": [
        "!git clone https://github.com/WongKinYiu/ScaledYOLOv4.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAvk6SYrCW5V"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "glossary.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "F3iYAh8nc23H",
        "lcYPAlBKb9li",
        "-zWT-tGLbokP",
        "ITNHJRkH_2MK",
        "ubGaH6xJdMaG",
        "xt09pmlwdRuR",
        "UUlrPw_rmoOU",
        "kjx0WDtjdZOm",
        "btzy_CbEdktJ",
        "gh3uEJNcdr-m",
        "1D9GfVjOdj6k",
        "0QPoARgedgIh",
        "ZIb-ILaZUYZV",
        "d8XdWTEKUOKt",
        "GZfXbfxQNROw"
      ],
      "authorship_tag": "ABX9TyM80yfs0HxJ7f4Kd9Q3DIh6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cksdlakstp12/deep_learning_study/blob/main/glossary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TM7_dwKPsSRo"
      },
      "source": [
        "# 기본 정보들"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3iYAh8nc23H"
      },
      "source": [
        "## 정밀도와 재현율 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YE3GrHVIvOaB"
      },
      "source": [
        "둘은 서로 trade-off하다.\n",
        "\n",
        "sklearn에서 precision_score , recall_score로 api제공\n",
        "\n",
        "정밀도 = TP / (FP + TP) => 예측값\n",
        "\n",
        "재현율 = TP / (FN + TP) => 실제값\n",
        "\n",
        "정밀도는 예측을 Positive로 한 대상중에 예측값과 실제값이 Positive로 일치한 데이터의 비율을 뜻한다. negative를 positive라고 예측하면 큰일나는 경우에 사용\n",
        "\n",
        "재현율은 실제값이 Positive인 대상중에 예측값과 실제값이 Positive로 일치한 데이터의 비율을 뜻한다.\n",
        "positive를 negative라고 예측하면 큰일나는 경우에 사용\n",
        "\n",
        "그냥 둘다 높을수록 좋다.\n",
        "\n",
        "정밀도 : 검출한 결과가 얼마나 정확하냐\n",
        "\n",
        "재현율 : 대상 물체들을 빠뜨리지 않고 얼마나 잘 잡아내냐"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcYPAlBKb9li"
      },
      "source": [
        "## 오버 피팅 막는 법"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPtxd1E1quQz"
      },
      "source": [
        "1. 드롭아웃\n",
        "\n",
        "2. 데이터 증강 or 데이터 추가\n",
        "\n",
        "3. 가중치 규제 (모델 크기 줄이기) \n",
        "\n",
        "4. 배치 정규화 : 드롭 아웃을 없앨 수 있다.\n",
        "\n",
        "5. 하이퍼파라미터 최적화 (앙상블, 강화학습, 랜덤 서칭, 그리드 서칭 등)\n",
        "\n",
        "6. ReLU activation 사용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zWT-tGLbokP"
      },
      "source": [
        "## 가중치 규제(Regularization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wx2eHP6mogcd"
      },
      "source": [
        "정의 : 모델 파라미터를 어느정도 규제해서 큰 모델의 경우 오버피팅 되는 것을 막아준다. 즉 너무 큰 모델의 경우 규제를 통해서 간단한 모델로 바꿔준다는 것이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ah2AkL-Dcgq1"
      },
      "source": [
        "unbiased 하다 : 모델의 가중치 규제를 적용하지 않아서 오버피팅의 위험은 있지만, 학습 오차는 줄어든다.\n",
        "\n",
        "bias 크면 = 학습 오차는 커지지만, 언더피팅 위험 증가\n",
        "\n",
        "variance 크면 = 학습 오차 낮아지지만, 오버피팅 위험 증가 \n",
        "\n",
        "\n",
        "Bias(편향) 에러가 높아지는 것은  많은 데이터를 고려하지 않아 (=모델이 너무 단순해)  정확한 예측을 하지 못하는 경우를 말하고,\n",
        "\n",
        "Variance(분산) 에러는 노이즈까지 전부 학습해(=모델이 너무 복잡해) 약간의 input에도 예측 Y 값이 크게 흔들리는 것을 말한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_awc6BoJcnz2"
      },
      "source": [
        "l1 규제와 l2 규제의 차이점 : abs(weight) or pow(weight, 2)\n",
        "\n",
        "l1 규제는 weight를 0으로 만드는 것이 가능해 weight selection이 가능하다.\n",
        "\n",
        "l2 규제는 weight간 상관관계를 잘 표현할 수 있다.\n",
        "\n",
        "이 둘을 조합해서 만든것이 elastic net 이다.\n",
        "\n",
        "하지만 보통 L2 규제를 사용한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITNHJRkH_2MK"
      },
      "source": [
        "## Interpolation(보간법)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgMC8df6_39S"
      },
      "source": [
        "주어진 몇개의 값을 통해서 함수를 추정해 새로운 입력에 대한 값을 구하기 위한 방식이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubGaH6xJdMaG"
      },
      "source": [
        "## Upsampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TG3wC7aHdov1"
      },
      "source": [
        "저해상도의 사진을 고해상도의 사진으로 만들기 위해서 사용됨.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xt09pmlwdRuR"
      },
      "source": [
        "## Residual block (= identity block)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Hwx5ZdBdpjN"
      },
      "source": [
        "입력을 출력에 더해서 학습(skip connection)하는 방법을 사용한 layer block이다. \n",
        "\n",
        "기존에 학습한 특징도 보존해서 추가적으로 학습을 한다. 이렇게 되면 각각의 레이어가 작은 정보를 추가적으로 학습하도록해 레이어의 부담을 줄일 수 있다. 즉 오픈북 시험처럼 이미 배운 내용을 책에서 볼 수 있기 때문에 추가적으로 모르는 것만 학습하면 된다는 것이다.\n",
        "\n",
        "vanishing gradient을 해결하는데 도움을 준다.\n",
        "\n",
        "GoogLeNet에서 사용한 bottle neck을 사용한다. 이를 통해서 파라미터의 수를 줄일 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUlrPw_rmoOU"
      },
      "source": [
        "## Convolution block"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfgVnVfumwXd"
      },
      "source": [
        "기존 residual block의 skip connection에 conv2d와 batch normalization을 추가한 블럭"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjx0WDtjdZOm"
      },
      "source": [
        "## Skip Connetcion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rP-4wowdp99"
      },
      "source": [
        "residual connection이랑 같은 말임."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btzy_CbEdktJ"
      },
      "source": [
        "## IoU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkekWXk8dqws"
      },
      "source": [
        "IoU란 ground truth box와 predicted box의 겹치는 부분과 두 box의 합집합의 비율이다.\n",
        "\n",
        "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbRLl5c%2Fbtq7CCYOqiv%2F7LdBiSRpRu0DRdfqxzQB9K%2Fimg.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gh3uEJNcdr-m"
      },
      "source": [
        "## AP, mAP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktXGuBKNPbr7"
      },
      "source": [
        "detection model의 경우 IoU를 이용해서 precision과 recall을 구한다. IoU의 값이 IoU threshold값보다 크면 TP로 하고 낮으면 FP로 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZbx53zkdwR5"
      },
      "source": [
        "클래스의 threshold를 변화해가면서 confidence를 이용해 precision과 recall을 구한다. 그후 precision-recall 곡선을 구하고 단조적인 그래프로 조정한다. 마지막으로 그래프의 아래 영역을 이용해 넓이를 구하고 그것을 AP(average precision)으로 사용한다. \n",
        "\n",
        "클래스가 여러개의 경우 각 클래스 별로 AP를 구한후 평균을 낸 mAP(mean average precision)을 사용한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1D9GfVjOdj6k"
      },
      "source": [
        "## Non-maximum Suppression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qdh2YnG5drU7"
      },
      "source": [
        "detection 수행시 한 object에 대해서 여러개의 bounding box가 예측될 수 있다. 하지만 우리는 하나의 가장 confidence가 높은 bounding box만 필요하므로 나머지 overlap된 box는 지우도록 한다. \n",
        "\n",
        "지우는 방법은 이 알고리즘을 따른다.\n",
        "\n",
        "<조건>\n",
        "1. proposals list B\n",
        "2. confidence list S\n",
        "3. threshold K\n",
        "4. final proposal list D\n",
        "\n",
        "<알고리즘>\n",
        "1. B에서 가장 confidence가 높은 proposal을 꺼내 D에 넣는다.\n",
        "2. 방금 꺼낸 proposal과 B에 남은 모든 proposal들의 IoU를 구한다.\n",
        "3. 2에서 구한 IoU가 K를 넘으면 B에서 삭제한다.\n",
        "4. 1로 돌아가서 B에 남은 proposal이 없을 때까지 진행한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QPoARgedgIh"
      },
      "source": [
        "## bounding box regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ua4LzUjgdqac"
      },
      "source": [
        "데이터에서 예측된 박스를 조정해주기 위해서 진행하는 회귀이다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMYWTViF_GMa"
      },
      "source": [
        "예측된 박스는\n",
        "\n",
        "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbLan7J%2Fbtq8hl4kfxt%2FPERWRtLoBwDn1TPb6YHgg0%2Fimg.png\">\n",
        "\n",
        "위와 같이 표현할 수 있고,\n",
        "\n",
        "Ground truth는\n",
        "\n",
        "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fv109p%2Fbtq8hpd7wRH%2Fr4d2LcAE20Zhw1pMwMsbwk%2Fimg.png\">\n",
        "\n",
        "위와 같이 표현할 수 있다.\n",
        "\n",
        "우리의 목표는 어떠한 함수를 이용해서 예측된 박스를 ground truth와 유사하게 이동시켜주는 것이다. 즉, \n",
        "\n",
        "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FecXyal%2Fbtq8kILgzY6%2FWdEGl6hz4o6KCbmt8Jeo0K%2Fimg.png\">\n",
        "\n",
        "위와 같이 함수를 사용해서 조정을 해주는 것이다. 위의 함수는 trainable 함수이며 학습이 된 후에는\n",
        "\n",
        "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FboeOWU%2Fbtq8lTlemiA%2Fjk6zTbPybE2PAP6neVvurK%2Fimg.png\">\n",
        "\n",
        "위와 같이 transformation을 진행한다. 위의 식은 아래의 그래프로 나타낼 수 있다.\n",
        "\n",
        "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdsYBrt%2Fbtq8gl4UIW9%2FnylkAuCe5Mx13FiOejmsg0%2Fimg.png\" width=\"500px\">\n",
        "\n",
        "위에서 말했듯이 함수 d는 trainable 함수이다. 함수 d의 식은\n",
        "\n",
        "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FclmJu7%2Fbtq8gmpdkt5%2FYdfPA8Wjdo8KPBk3A0kOn1%2Fimg.png\">\n",
        "\n",
        "위와 같고 W는 trainable weight이며 뒤에 곱해지는 것은 CNN의 pool5 레이어에서 구한 feature vector이다. 이를 통해서 스칼라를 구하고 비용함수를 통해서 오차를 구하고 역전파를 진행한다.\n",
        "\n",
        "오차함수의 식은 아래와 같다.\n",
        "\n",
        "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdBaIHR%2Fbtq8kIEyOtR%2FqJUA1ohrLQBykN8Rog1bGk%2Fimg.png\">\n",
        "\n",
        "위의 식은 일반적인 MSE와 같지만 L2 regularization을 적용한 것이다. 논문에서는 람다값을 1000으로 설정했다고 한다.\n",
        "\n",
        "여기서 regression target t는 아래와 같이 정의한다.\n",
        "\n",
        "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FIh4fG%2Fbtq8mk31n23%2F8FFzr8JBi00C1z2cZzyFp0%2Fimg.png\">\n",
        "\n",
        "위의 t값은 label값이라고 봐도 된다.\n",
        "\n",
        "또한 bounding box regression을 모든 경우에 적용하지 않고 ground truth box와 predict box의 IoU가 0.6 이상일 경우만 적용한다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIb-ILaZUYZV"
      },
      "source": [
        "## GIoU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azuPDMgJUccs"
      },
      "source": [
        "ground truth box와 predicted box가 전혀 겹치지 않을 때 기존의 IoU의 경우에는 이를 측정하지 못하고 모두 0이라고 했다. 하지만 GIoU는 이 단점을 정량적으로 표현하는 방법이라고 할 수 있다. GIoU는 아래와 같다. \n",
        "\n",
        "<img src=\"https://gaussian37.github.io/assets/img/vision/detection/giou/5.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sesTBlDGlNo"
      },
      "source": [
        "실제로 IoU 대신 GIoU를 사용했을 때 대부분의 경우 AP가 증가했다고 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8XdWTEKUOKt"
      },
      "source": [
        "## Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXECHbcVUSG9"
      },
      "source": [
        "context vector를 dynamic하게 매 decode 시기마다 만들어주기 위한 방법이다. seq2seq에서는 RNN cell의 모든 state값들을 fully connected layer를 사용해서 attention score를 구한다. 이렇게 구해진 attention score를 이용해서 state vector와 곱해 새로운 context vector를 만든다. \n",
        "\n",
        "여기서 주의할 점이 있다. context vector를 만들기 위해서 FC layer를 통과한 값과 더해지는 값이 있는데 바로 디코더에서 나온 output vector를 FC layer를 통과시킨 값이다. 이것을 softmax layer를 통과시켜서 attention score를 구한다. 처음에는 디코더의 output vector가 없으므로 인코더의 마지막 state vector값을 이용한다.\n",
        "\n",
        "<img src=\"https://media.vlpt.us/images/kgh732/post/2b940db8-cbf8-44ca-bbdc-4543b3fbc5e1/image.png\" width=\"650px\">\n",
        "\n",
        "attention score 계산 방법은 아래와 같고,\n",
        "\n",
        "<img src=\"https://media.vlpt.us/images/kgh732/post/2b0dd1a2-2981-403d-9b8f-d6f3564881f4/image.png\" width=\"650px\">\n",
        "\n",
        "alignment model a는 3가지 있지만 가장 간단한 모델만 설명하면, 두 hidden state vector를 Dot Product하는 것이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZfXbfxQNROw"
      },
      "source": [
        "## BLEU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Gu6EdfeNTZy"
      },
      "source": [
        "n-gram에 기반한 자연어 처리 모델의 성능 평가 지표이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oock9nU9CbVZ"
      },
      "source": [
        "## imagenet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kOfU2MDCbSJ"
      },
      "source": [
        "방대하고 질 좋은 오픈 소스 이미지 데이터로서 classification과 detection 학습에 필요한 label을 포한하고 있다. 최근에는 imagenet을 이용해서 모델을 평가하기도 하며 pre-trained model의 학습 데이터로서 채용되기도 한다."
      ]
    }
  ]
}
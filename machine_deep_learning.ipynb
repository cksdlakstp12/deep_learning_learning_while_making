{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "machine_deep_learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cksdlakstp12/deep_learning_study/blob/main/machine_deep_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKE9ecwQD6f4"
      },
      "source": [
        "# **Linear Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uAZZ4z7D5Lc"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def numerical_derivative(f, x):\n",
        "  delta_x = 1e-4\n",
        "  grad = np.zeros_like(x)\n",
        "\n",
        "  it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
        "\n",
        "  while not it.finished:\n",
        "    idx = it.multi_index\n",
        "\n",
        "    tmp_val = x[idx]\n",
        "    x[idx] = float(tmp_val) + delta_x\n",
        "    fx1 = f(x)\n",
        "\n",
        "    x[idx] = tmp_val - delta_x\n",
        "    fx2 = f(x)\n",
        "    grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
        "\n",
        "    x[idx] = tmp_val\n",
        "    it.iternext()\n",
        "\n",
        "  return grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pw9PSxkbIFmG"
      },
      "source": [
        "단일변수 데이터에 대한 선형회귀"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9I6mOhaz4zJr",
        "outputId": "cc8b669c-9a64-43c0-ae4c-318152bebd09"
      },
      "source": [
        "# 데이터 값 초기화\n",
        "x_data = np.array([1,2,3,4,5]).reshape(5, 1)\n",
        "t_data = np.array([2,3,4,5,6]).reshape(5, 1)\n",
        "\n",
        "# 행렬값으로 데이터가 주어지면 아래처럼 분리하여 사용한다.\n",
        "# raw_data = np.array([[1,2], [3,4], [5,6]])\n",
        "# x = raw_data[:, 0].reshape(3, 1)\n",
        "# print(x)\n",
        "\n",
        "# W, b 초기화\n",
        "W = np.random.rand(1, 1)\n",
        "b = np.random.rand(1)\n",
        "print(\"W = \", W, \", W.shape = \", W.shape, \", b = \", b, \", b.shape = \", b.shape)\n",
        "\n",
        "# 손실함수 E(W, b) 정의\n",
        "def error_val(x, t):\n",
        "  y = np.dot(x, W) + b\n",
        "\n",
        "  return (np.sum((t - y)**2)) / (len(x))\n",
        "\n",
        "# 학습을 마친 후 값을 예측하기 위한 함수\n",
        "def predict(x):\n",
        "  y = np.dot(x, W) + b\n",
        "\n",
        "  return y\n",
        "\n",
        "# 학습 시키기\n",
        "learning_rate = 1e-2\n",
        "\n",
        "f = lambda x : error_val(x_data, t_data)\n",
        "\n",
        "print(\"initial error value = \", error_val(x_data, t_data), \"initial W = \", W, \"\\n\", \", b = \", b)\n",
        "\n",
        "for step in range(8001):\n",
        "  W -= learning_rate*numerical_derivative(f, W)\n",
        "\n",
        "  b -= learning_rate*numerical_derivative(f, b)\n",
        "\n",
        "  if(step % 400 == 0):\n",
        "    print(\"step = \", step, \"error value = \", error_val(x_data, t_data), \"W = \", W, \"b = \", b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W =  [[0.09212446]] , W.shape =  (1, 1) , b =  [0.04477643] , b.shape =  (1,)\n",
            "initial error value =  15.182414724628032 initial W =  [[0.09212446]] \n",
            " , b =  [0.04477643]\n",
            "step =  0 error value =  8.967138037507674 W =  [[0.34917049]] b =  [0.10293067]\n",
            "step =  400 error value =  0.005915818790132611 W =  [[1.0499464]] b =  [0.81972179]\n",
            "step =  800 error value =  0.00037746421297051773 W =  [[1.01261638]] b =  [0.95446203]\n",
            "step =  1200 error value =  2.408444834569828e-05 W =  [[1.00318688]] b =  [0.98849718]\n",
            "step =  1600 error value =  1.536730191058976e-06 W =  [[1.000805]] b =  [0.99709441]\n",
            "step =  2000 error value =  9.805247129682713e-08 W =  [[1.00020334]] b =  [0.99926605]\n",
            "step =  2400 error value =  6.256327352246657e-09 W =  [[1.00005136]] b =  [0.99981461]\n",
            "step =  2800 error value =  3.9919067231342553e-10 W =  [[1.00001297]] b =  [0.99995317]\n",
            "step =  3200 error value =  2.5470724901871547e-11 W =  [[1.00000328]] b =  [0.99998817]\n",
            "step =  3600 error value =  1.6251828305582999e-12 W =  [[1.00000083]] b =  [0.99999701]\n",
            "step =  4000 error value =  1.0369627263379417e-13 W =  [[1.00000021]] b =  [0.99999925]\n",
            "step =  4400 error value =  6.6164352438288926e-15 W =  [[1.00000005]] b =  [0.99999981]\n",
            "step =  4800 error value =  4.2216767913462317e-16 W =  [[1.00000001]] b =  [0.99999995]\n",
            "step =  5200 error value =  2.6936794099173408e-17 W =  [[1.]] b =  [0.99999999]\n",
            "step =  5600 error value =  1.7187260928928572e-18 W =  [[1.]] b =  [1.]\n",
            "step =  6000 error value =  1.096650464339079e-19 W =  [[1.]] b =  [1.]\n",
            "step =  6400 error value =  6.997259786857294e-21 W =  [[1.]] b =  [1.]\n",
            "step =  6800 error value =  4.464603544131992e-22 W =  [[1.]] b =  [1.]\n",
            "step =  7200 error value =  2.84868882983201e-23 W =  [[1.]] b =  [1.]\n",
            "step =  7600 error value =  1.818995164822903e-24 W =  [[1.]] b =  [1.]\n",
            "step =  8000 error value =  1.1644984230940507e-25 W =  [[1.]] b =  [1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CkXRSiRIKpG"
      },
      "source": [
        "학습에 대한 결과"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKptuyhu4zOl",
        "outputId": "1366523f-d6e4-4306-d74b-b5bf66ffef3f"
      },
      "source": [
        "predict(43)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[44.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSw7LnHfFWH9"
      },
      "source": [
        "다변수 데이터에 대한 선형회귀"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63DqTfSr4zRd",
        "outputId": "a7f36ea5-2645-4817-9a37-faf7409d4ae4"
      },
      "source": [
        "loaded_data = np.array(\n",
        "[[73,\t80,\t75,\t152],\n",
        "[93,\t88,\t93,\t185],\n",
        "[89,\t91,\t90,\t180],\n",
        "[96,\t98,\t100, 196],\n",
        "[73,\t66,\t70,\t142],\n",
        "[53,\t46,\t55,\t101],\n",
        "[69,\t74,\t77,\t149],\n",
        "[47,\t56,\t60,\t115],\n",
        "[87,\t79,\t90,\t175],\n",
        "[79,\t70,\t88,\t164],\n",
        "[69,\t70,\t73,\t141],\n",
        "[70,\t65,\t74,\t141],\n",
        "[93,\t95,\t91,\t184],\n",
        "[79,\t80,\t73,\t152],\n",
        "[70,\t73,\t78,\t148],\n",
        "[93,\t89,\t96,\t192],\n",
        "[78,\t75,\t68,\t147],\n",
        "[81,\t90,\t93,\t183],\n",
        "[88,\t92,\t86,\t177],\n",
        "[78,\t83,\t77,\t159],\n",
        "[82,\t86,\t90,\t177],\n",
        "[86,\t82,\t89,\t175],\n",
        "[78,\t83,\t85,\t175],\n",
        "[76,\t83,\t71,\t149],\n",
        "[96,\t93,\t95,\t192]])\n",
        "\n",
        "# 데이터 분리\n",
        "x_data = loaded_data[:, 0:-1]\n",
        "t_data = loaded_data[:, [-1]]\n",
        "\n",
        "# 가중치, 바이어스 초기화\n",
        "W = np.random.rand(3, 1)\n",
        "b = np.random.rand(1)\n",
        "\n",
        "# 학습 시키기\n",
        "learning_rate = 1e-5\n",
        "\n",
        "f = lambda x : error_val(x_data, t_data)\n",
        "\n",
        "print(\"initial error value = \", error_val(x_data, t_data), \"initial W = \", W, \"\\n\", \", b = \", b)\n",
        "\n",
        "for step in range(10001):\n",
        "  # 가중치 업데이트\n",
        "  W -= learning_rate*numerical_derivative(f, W)\n",
        "  # 바이어스 업데이트\n",
        "  b -= learning_rate*numerical_derivative(f, b)\n",
        "\n",
        "  if(step % 400 == 0):\n",
        "    print(\"step = \", step, \"error value = \", error_val(x_data, t_data), \"W = \", W, \"b = \", b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initial error value =  586.9751644207256 initial W =  [[0.94124275]\n",
            " [0.49295048]\n",
            " [0.88508096]] \n",
            " , b =  [0.13824975]\n",
            "step =  0 error value =  223.9969126915746 W =  [[0.90277165]\n",
            " [0.45440214]\n",
            " [0.84573199]] b =  [0.13796016]\n",
            "step =  400 error value =  10.089270413185375 W =  [[0.79644289]\n",
            " [0.39938134]\n",
            " [0.82534631]] b =  [0.13721525]\n",
            "step =  800 error value =  9.31653873802194 W =  [[0.75414147]\n",
            " [0.40504113]\n",
            " [0.86093069]] b =  [0.13687221]\n",
            "step =  1200 error value =  8.700015858381073 W =  [[0.71592984]\n",
            " [0.41126448]\n",
            " [0.89199014]] b =  [0.13648871]\n",
            "step =  1600 error value =  8.206543548122433 W =  [[0.68140822]\n",
            " [0.41781829]\n",
            " [0.91914093]] b =  [0.13606983]\n",
            "step =  2000 error value =  7.81042464587616 W =  [[0.65021657]\n",
            " [0.42452085]\n",
            " [0.94291045]] b =  [0.13561997]\n",
            "step =  2400 error value =  7.491636238956842 W =  [[0.62203063]\n",
            " [0.43123226]\n",
            " [0.96375054]] b =  [0.13514295]\n",
            "step =  2800 error value =  7.234496786670427 W =  [[0.59655815]\n",
            " [0.43784638]\n",
            " [0.98204887]] b =  [0.13464208]\n",
            "step =  3200 error value =  7.026665967055875 W =  [[0.57353575]\n",
            " [0.44428434]\n",
            " [0.99813847]] b =  [0.13412024]\n",
            "step =  3600 error value =  6.858389657507395 W =  [[0.55272596]\n",
            " [0.45048912]\n",
            " [1.01230582]] b =  [0.13357994]\n",
            "step =  4000 error value =  6.721926502384866 W =  [[0.5339146 ]\n",
            " [0.45642116]\n",
            " [1.02479769]] b =  [0.13302337]\n",
            "step =  4400 error value =  6.611109760999526 W =  [[0.51690848]\n",
            " [0.4620547 ]\n",
            " [1.03582698]] b =  [0.13245244]\n",
            "step =  4800 error value =  6.521010531932568 W =  [[0.5015333 ]\n",
            " [0.46737487]\n",
            " [1.04557762]] b =  [0.13186881]\n",
            "step =  5200 error value =  6.447677404062812 W =  [[0.48763175]\n",
            " [0.47237525]\n",
            " [1.05420872]] b =  [0.13127397]\n",
            "step =  5600 error value =  6.387934075173409 W =  [[0.47506183]\n",
            " [0.47705596]\n",
            " [1.06185818]] b =  [0.13066918]\n",
            "step =  6000 error value =  6.339221203872339 W =  [[0.46369537]\n",
            " [0.48142201]\n",
            " [1.06864563]] b =  [0.13005558]\n",
            "step =  6400 error value =  6.299472216199141 W =  [[0.45341661]\n",
            " [0.4854821 ]\n",
            " [1.07467508]] b =  [0.12943416]\n",
            "step =  6800 error value =  6.2670153283273455 W =  [[0.44412103]\n",
            " [0.48924754]\n",
            " [1.08003703]] b =  [0.1288058]\n",
            "step =  7200 error value =  6.240495923743368 W =  [[0.43571422]\n",
            " [0.49273147]\n",
            " [1.08481038]] b =  [0.12817127]\n",
            "step =  7600 error value =  6.218814818050907 W =  [[0.42811089]\n",
            " [0.49594822]\n",
            " [1.08906403]] b =  [0.12753125]\n",
            "step =  8000 error value =  6.201078987012545 W =  [[0.42123399]\n",
            " [0.49891276]\n",
            " [1.0928582 ]] b =  [0.12688635]\n",
            "step =  8400 error value =  6.186562117247726 W =  [[0.41501389]\n",
            " [0.50164036]\n",
            " [1.09624565]] b =  [0.12623709]\n",
            "step =  8800 error value =  6.174672931902793 W =  [[0.40938769]\n",
            " [0.50414625]\n",
            " [1.09927262]] b =  [0.12558396]\n",
            "step =  9200 error value =  6.164929694821257 W =  [[0.40429853]\n",
            " [0.50644539]\n",
            " [1.10197974]] b =  [0.12492737]\n",
            "step =  9600 error value =  6.1569396421981 W =  [[0.39969502]\n",
            " [0.50855233]\n",
            " [1.10440273]] b =  [0.1242677]\n",
            "step =  10000 error value =  6.15038235674439 W =  [[0.3955307 ]\n",
            " [0.51048107]\n",
            " [1.10657306]] b =  [0.12360528]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsnmxBPEIOBX"
      },
      "source": [
        "학습에 대한 결과"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpCXmOe04zUf",
        "outputId": "544390ff-931c-46d5-d4e5-a79b4b812c32"
      },
      "source": [
        "predict(np.array([100, 98, 81]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([179.33623765])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJ5NChg1EUbb"
      },
      "source": [
        "# **Classification**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kloRMilyI_yG"
      },
      "source": [
        "단일 변수 classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LB_z1RgADrHV",
        "outputId": "004a0054-ee11-49bf-c602-6e4ac9cbe0fb"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "x_data = np.array([2,4,6,8,10,12,14,16,18,20]).reshape(10, 1)\n",
        "t_data = np.array([0,0,0,0,0,0,1,1,1,1]).reshape(10, 1)\n",
        "\n",
        "W = np.random.rand(1, 1)\n",
        "b = np.random.rand(1)\n",
        "\n",
        "# sigmoid 함수(확률적인 값이 나오도록 함) 정의\n",
        "def sigmoid(x):\n",
        "  return 1 / (1+np.exp(-x))\n",
        "\n",
        "# 손실함수 정의\n",
        "def closs_entropy(x, t):\n",
        "  # log 값이 0일때 무한대가 되는 것을 방지하는 역할\n",
        "  delta = 1e-7\n",
        "\n",
        "  z = np.dot(x, W) + b\n",
        "  y = sigmoid(z)\n",
        "\n",
        "  return -np.sum(t*np.log(y+delta) + (1-t)*np.log(1-y+delta))\n",
        "\n",
        "def predict(x):\n",
        "  z = np.dot(x, W) + b\n",
        "  y = sigmoid(z)\n",
        "\n",
        "  if y >= 0.5: result = 1\n",
        "  else: result = 0\n",
        "\n",
        "  return y, result\n",
        "\n",
        "learning_rate = 1e-2\n",
        "\n",
        "f = lambda x : closs_entropy(x_data, t_data)\n",
        "\n",
        "for step in range(10001):\n",
        "  \n",
        "  W -= learning_rate*numerical_derivative(f, W)\n",
        "  b -= learning_rate*numerical_derivative(f, b)\n",
        "\n",
        "  if(step % 400 == 0):\n",
        "    print(\"step = \", step, \"error value = \", closs_entropy(x_data, t_data), \"W = \", W, \"b = \", b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step =  0 error value =  8.194303612290408 W =  [[0.04891791]] b =  [0.50954889]\n",
            "step =  400 error value =  3.075809006918589 W =  [[0.43407142]] b =  [-4.16874331]\n",
            "step =  800 error value =  1.775150109703544 W =  [[0.45553621]] b =  [-5.67004601]\n",
            "step =  1200 error value =  1.512988384520026 W =  [[0.53235799]] b =  [-6.69290144]\n",
            "step =  1600 error value =  1.3491029295049894 W =  [[0.59332263]] b =  [-7.50241748]\n",
            "step =  2000 error value =  1.2335109495214638 W =  [[0.64464838]] b =  [-8.18246182]\n",
            "step =  2400 error value =  1.145892534600995 W =  [[0.68941558]] b =  [-8.77456013]\n",
            "step =  2800 error value =  1.0762246496595103 W =  [[0.72939182]] b =  [-9.30251959]\n",
            "step =  3200 error value =  1.018912213605995 W =  [[0.76569286]] b =  [-9.78135211]\n",
            "step =  3600 error value =  0.970549892219292 W =  [[0.7990719]] b =  [-10.22118031]\n",
            "step =  4000 error value =  0.9289281293946058 W =  [[0.83006343]] b =  [-10.62917923]\n",
            "step =  4400 error value =  0.8925407274492655 W =  [[0.85906165]] b =  [-11.01063499]\n",
            "step =  4800 error value =  0.8603198546781377 W =  [[0.88636638]] b =  [-11.36956393]\n",
            "step =  5200 error value =  0.8314838677039216 W =  [[0.91221145]] b =  [-11.70909533]\n",
            "step =  5600 error value =  0.8054452125740453 W =  [[0.93678309]] b =  [-12.03171891]\n",
            "step =  6000 error value =  0.7817522194139934 W =  [[0.96023222]] b =  [-12.33945091]\n",
            "step =  6400 error value =  0.7600509549466024 W =  [[0.98268305]] b =  [-12.63394904]\n",
            "step =  6800 error value =  0.7400594338130106 W =  [[1.00423911]] b =  [-12.91659423]\n",
            "step =  7200 error value =  0.7215497123370976 W =  [[1.02498773]] b =  [-13.18855017]\n",
            "step =  7600 error value =  0.7043351622307426 W =  [[1.04500327]] b =  [-13.45080742]\n",
            "step =  8000 error value =  0.6882612384260278 W =  [[1.06434968]] b =  [-13.70421681]\n",
            "step =  8400 error value =  0.6731986588353581 W =  [[1.08308234]] b =  [-13.94951508]\n",
            "step =  8800 error value =  0.6590382834858706 W =  [[1.10124957]] b =  [-14.18734479]\n",
            "step =  9200 error value =  0.6456872131399504 W =  [[1.11889386]] b =  [-14.41827008]\n",
            "step =  9600 error value =  0.6330657775941494 W =  [[1.13605271]] b =  [-14.64278917]\n",
            "step =  10000 error value =  0.62110518281382 W =  [[1.15275946]] b =  [-14.8613445]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZclDMsoDrJo",
        "outputId": "5e1efef1-21a3-4bd1-af4b-815364133d39"
      },
      "source": [
        "(real_val, logical_val) = predict(3)\n",
        "\n",
        "print(real_val, logical_val)\n",
        "\n",
        "(real_val, logical_val) = predict(17)\n",
        "\n",
        "print(real_val, logical_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.11610862e-05]] 0\n",
            "[[0.9912989]] 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNQUgsClJC8_"
      },
      "source": [
        "다변수 classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Wxak7dzDrM3",
        "outputId": "63d08f4c-60da-4706-f8c5-7122a0245075"
      },
      "source": [
        "x_data = np.array([2,4,4,11,6,6,8,5,10,7,12,16,14,8,16,3,18,7]).reshape(9, 2)\n",
        "t_data = np.array([0,0,0,0,1,1,1,1,1]).reshape(9, 1)\n",
        "\n",
        "W = np.random.rand(2, 1)\n",
        "b = np.random.rand(1)\n",
        "\n",
        "# sigmoid 함수(확률적인 값이 나오도록 함) 정의\n",
        "def sigmoid(x):\n",
        "  return 1 / (1+np.exp(-x))\n",
        "\n",
        "# 손실함수 정의\n",
        "def closs_entropy(x, t):\n",
        "  # log 값이 0일때 무한대가 되는 것을 방지하는 역할\n",
        "  delta = 1e-7\n",
        "\n",
        "  z = np.dot(x, W) + b\n",
        "  y = sigmoid(z)\n",
        "\n",
        "  return -np.sum(t*np.log(y+delta) + (1-t)*np.log(1-y+delta))\n",
        "\n",
        "def predict(x):\n",
        "  z = np.dot(x, W) + b\n",
        "  y = sigmoid(z)\n",
        "\n",
        "  if y >= 0.5: result = 1\n",
        "  else: result = 0\n",
        "\n",
        "  return y, result\n",
        "\n",
        "learning_rate = 1e-2\n",
        "\n",
        "f = lambda x : closs_entropy(x_data, t_data)\n",
        "\n",
        "for step in range(80001):\n",
        "  \n",
        "  W -= learning_rate*numerical_derivative(f, W)\n",
        "  b -= learning_rate*numerical_derivative(f, b)\n",
        "\n",
        "  if(step % 400 == 0):\n",
        "    print(\"step = \", step, \"error value = \", closs_entropy(x_data, t_data), \"W = \", W, \"b = \", b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step =  0 error value =  20.884071742874628 W =  [[0.01569609]\n",
            " [0.72925104]] b =  [0.37098096]\n",
            "step =  400 error value =  2.231682064605912 W =  [[ 0.42561913]\n",
            " [-0.08364285]] b =  [-2.70343155]\n",
            "step =  800 error value =  1.5749200322094783 W =  [[ 0.54005897]\n",
            " [-0.02472298]] b =  [-4.31255978]\n",
            "step =  1200 error value =  1.2711506683534914 W =  [[0.62637437]\n",
            " [0.01012238]] b =  [-5.41107396]\n",
            "step =  1600 error value =  1.092555266672408 W =  [[0.69619197]\n",
            " [0.03507406]] b =  [-6.25424012]\n",
            "step =  2000 error value =  0.9726978393344226 W =  [[0.75511517]\n",
            " [0.05500765]] b =  [-6.94517749]\n",
            "step =  2400 error value =  0.8852602016755068 W =  [[0.80624893]\n",
            " [0.07210172]] b =  [-7.53535597]\n",
            "step =  2800 error value =  0.8177317592174582 W =  [[0.85149585]\n",
            " [0.08748766]] b =  [-8.05400323]\n",
            "step =  3200 error value =  0.763391928402125 W =  [[0.89211023]\n",
            " [0.10181156]] b =  [-8.5192382]\n",
            "step =  3600 error value =  0.7182972260760591 W =  [[0.92896641]\n",
            " [0.11546591]] b =  [-8.94303596]\n",
            "step =  4000 error value =  0.6799736027337863 W =  [[0.96270158]\n",
            " [0.12869813]] b =  [-9.33370832]\n",
            "step =  4400 error value =  0.6467853099830865 W =  [[0.99379757]\n",
            " [0.14166661]] b =  [-9.69725203]\n",
            "step =  4800 error value =  0.6176042579556346 W =  [[1.02263033]\n",
            " [0.1544718 ]] b =  [-10.03813107]\n",
            "step =  5200 error value =  0.5916250695441179 W =  [[1.04950119]\n",
            " [0.16717484]] b =  [-10.35975516]\n",
            "step =  5600 error value =  0.56825592627689 W =  [[1.07465727]\n",
            " [0.17980939]] b =  [-10.66478544]\n",
            "step =  6000 error value =  0.5470511891917433 W =  [[1.09830514]\n",
            " [0.19238969]] b =  [-10.95533701]\n",
            "step =  6400 error value =  0.5276681903805326 W =  [[1.12062003]\n",
            " [0.20491642]] b =  [-11.23311756]\n",
            "step =  6800 error value =  0.5098386008693124 W =  [[1.14175236]\n",
            " [0.21738107]] b =  [-11.49952469]\n",
            "step =  7200 error value =  0.4933489100704077 W =  [[1.16183221]\n",
            " [0.22976936]] b =  [-11.75571619]\n",
            "step =  7600 error value =  0.4780267830914993 W =  [[1.18097269]\n",
            " [0.24206388]] b =  [-12.00266156]\n",
            "step =  8000 error value =  0.46373131720873967 W =  [[1.19927238]\n",
            " [0.25424609]] b =  [-12.2411807]\n",
            "step =  8400 error value =  0.45034595006987077 W =  [[1.21681729]\n",
            " [0.26629783]] b =  [-12.47197339]\n",
            "step =  8800 error value =  0.4377732117131184 W =  [[1.2336825 ]\n",
            " [0.27820229]] b =  [-12.69564192]\n",
            "step =  9200 error value =  0.42593078412318636 W =  [[1.24993347]\n",
            " [0.28994468]] b =  [-12.91270892]\n",
            "step =  9600 error value =  0.4147485042665858 W =  [[1.26562729]\n",
            " [0.30151258]] b =  [-13.1236313]\n",
            "step =  10000 error value =  0.4041660583651966 W =  [[1.2808137 ]\n",
            " [0.31289602]] b =  [-13.32881135]\n",
            "step =  10400 error value =  0.39413118940323527 W =  [[1.29553608]\n",
            " [0.32408742]] b =  [-13.52860574]\n",
            "step =  10800 error value =  0.3845982901915562 W =  [[1.30983226]\n",
            " [0.33508144]] b =  [-13.72333263]\n",
            "step =  11200 error value =  0.375527289096275 W =  [[1.3237353 ]\n",
            " [0.34587476]] b =  [-13.91327756]\n",
            "step =  11600 error value =  0.36688276000147135 W =  [[1.33727416]\n",
            " [0.35646579]] b =  [-14.0986982]\n",
            "step =  12000 error value =  0.3586332055506207 W =  [[1.35047427]\n",
            " [0.36685445]] b =  [-14.27982828]\n",
            "step =  12400 error value =  0.35075047536077353 W =  [[1.36335803]\n",
            " [0.37704186]] b =  [-14.45688083]\n",
            "step =  12800 error value =  0.34320929017040946 W =  [[1.37594526]\n",
            " [0.38703018]] b =  [-14.63005087]\n",
            "step =  13200 error value =  0.33598684973666626 W =  [[1.38825356]\n",
            " [0.39682235]] b =  [-14.79951761]\n",
            "step =  13600 error value =  0.32906250741391657 W =  [[1.40029862]\n",
            " [0.40642193]] b =  [-14.96544643]\n",
            "step =  14000 error value =  0.32241749819345217 W =  [[1.41209452]\n",
            " [0.41583295]] b =  [-15.12799038]\n",
            "step =  14400 error value =  0.31603470989722154 W =  [[1.42365393]\n",
            " [0.42505978]] b =  [-15.28729161]\n",
            "step =  14800 error value =  0.30989848943990844 W =  [[1.43498829]\n",
            " [0.43410703]] b =  [-15.44348248]\n",
            "step =  15200 error value =  0.3039944777753694 W =  [[1.44610803]\n",
            " [0.44297945]] b =  [-15.59668656]\n",
            "step =  15600 error value =  0.2983094684576255 W =  [[1.45702264]\n",
            " [0.45168187]] b =  [-15.74701953]\n",
            "step =  16000 error value =  0.292831285763673 W =  [[1.46774083]\n",
            " [0.46021913]] b =  [-15.89458988]\n",
            "step =  16400 error value =  0.2875486791209859 W =  [[1.47827062]\n",
            " [0.46859608]] b =  [-16.03949958]\n",
            "step =  16800 error value =  0.28245123120453247 W =  [[1.48861941]\n",
            " [0.47681748]] b =  [-16.18184465]\n",
            "step =  17200 error value =  0.2775292775596229 W =  [[1.49879407]\n",
            " [0.48488804]] b =  [-16.32171567]\n",
            "step =  17600 error value =  0.2727738359966569 W =  [[1.508801  ]\n",
            " [0.49281232]] b =  [-16.45919823]\n",
            "step =  18000 error value =  0.2681765443141073 W =  [[1.51864615]\n",
            " [0.50059483]] b =  [-16.59437331]\n",
            "step =  18400 error value =  0.2637296051550767 W =  [[1.5283351]\n",
            " [0.5082399]] b =  [-16.72731762]\n",
            "step =  18800 error value =  0.25942573700352267 W =  [[1.53787311]\n",
            " [0.51575174]] b =  [-16.85810398]\n",
            "step =  19200 error value =  0.25525813048875484 W =  [[1.54726509]\n",
            " [0.52313445]] b =  [-16.98680153]\n",
            "step =  19600 error value =  0.25122040929921224 W =  [[1.55651571]\n",
            " [0.53039196]] b =  [-17.11347603]\n",
            "step =  20000 error value =  0.24730659511520808 W =  [[1.56562936]\n",
            " [0.53752808]] b =  [-17.2381901]\n",
            "step =  20400 error value =  0.24351107605910322 W =  [[1.5746102 ]\n",
            " [0.54454648]] b =  [-17.36100339]\n",
            "step =  20800 error value =  0.2398285782358227 W =  [[1.58346219]\n",
            " [0.55145069]] b =  [-17.48197281]\n",
            "step =  21200 error value =  0.236254139997507 W =  [[1.59218908]\n",
            " [0.55824411]] b =  [-17.6011527]\n",
            "step =  21600 error value =  0.23278308861740457 W =  [[1.60079445]\n",
            " [0.56493002]] b =  [-17.71859498]\n",
            "step =  22000 error value =  0.22941101910128195 W =  [[1.6092817 ]\n",
            " [0.57151156]] b =  [-17.83434929]\n",
            "step =  22400 error value =  0.2261337749007635 W =  [[1.61765409]\n",
            " [0.57799176]] b =  [-17.94846315]\n",
            "step =  22800 error value =  0.22294743032350117 W =  [[1.62591472]\n",
            " [0.58437355]] b =  [-18.06098209]\n",
            "step =  23200 error value =  0.21984827446141464 W =  [[1.63406658]\n",
            " [0.59065971]] b =  [-18.17194971]\n",
            "step =  23600 error value =  0.21683279648020562 W =  [[1.64211251]\n",
            " [0.59685294]] b =  [-18.28140786]\n",
            "step =  24000 error value =  0.2138976721324745 W =  [[1.65005523]\n",
            " [0.60295584]] b =  [-18.38939668]\n",
            "step =  24400 error value =  0.21103975137323133 W =  [[1.65789738]\n",
            " [0.60897089]] b =  [-18.49595474]\n",
            "step =  24800 error value =  0.2082560469705532 W =  [[1.66564146]\n",
            " [0.6149005 ]] b =  [-18.60111908]\n",
            "step =  25200 error value =  0.20554372401640197 W =  [[1.6732899 ]\n",
            " [0.62074697]] b =  [-18.70492532]\n",
            "step =  25600 error value =  0.20290009025332367 W =  [[1.68084503]\n",
            " [0.62651252]] b =  [-18.80740774]\n",
            "step =  26000 error value =  0.2003225871418075 W =  [[1.68830908]\n",
            " [0.63219928]] b =  [-18.90859931]\n",
            "step =  26400 error value =  0.19780878160133553 W =  [[1.6956842 ]\n",
            " [0.63780933]] b =  [-19.00853179]\n",
            "step =  26800 error value =  0.1953563583651007 W =  [[1.70297249]\n",
            " [0.64334463]] b =  [-19.10723578]\n",
            "step =  27200 error value =  0.19296311289476037 W =  [[1.71017595]\n",
            " [0.6488071 ]] b =  [-19.20474078]\n",
            "step =  27600 error value =  0.19062694480672102 W =  [[1.7172965 ]\n",
            " [0.65419859]] b =  [-19.30107523]\n",
            "step =  28000 error value =  0.18834585176669882 W =  [[1.72433603]\n",
            " [0.65952085]] b =  [-19.39626658]\n",
            "step =  28400 error value =  0.18611792381327066 W =  [[1.73129633]\n",
            " [0.66477561]] b =  [-19.49034133]\n",
            "step =  28800 error value =  0.18394133807521007 W =  [[1.73817914]\n",
            " [0.66996452]] b =  [-19.58332505]\n",
            "step =  29200 error value =  0.18181435385030537 W =  [[1.74498616]\n",
            " [0.67508916]] b =  [-19.67524246]\n",
            "step =  29600 error value =  0.1797353080170203 W =  [[1.75171902]\n",
            " [0.68015108]] b =  [-19.76611745]\n",
            "step =  30000 error value =  0.17770261075237692 W =  [[1.75837929]\n",
            " [0.68515176]] b =  [-19.85597311]\n",
            "step =  30400 error value =  0.17571474153229796 W =  [[1.7649685 ]\n",
            " [0.69009264]] b =  [-19.94483178]\n",
            "step =  30800 error value =  0.1737702453927173 W =  [[1.77148813]\n",
            " [0.69497509]] b =  [-20.03271507]\n",
            "step =  31200 error value =  0.1718677294314664 W =  [[1.77793962]\n",
            " [0.69980047]] b =  [-20.11964391]\n",
            "step =  31600 error value =  0.17000585953285435 W =  [[1.78432436]\n",
            " [0.70457005]] b =  [-20.20563854]\n",
            "step =  32000 error value =  0.1681833572985619 W =  [[1.7906437]\n",
            " [0.7092851]] b =  [-20.2907186]\n",
            "step =  32400 error value =  0.16639899716955514 W =  [[1.79689894]\n",
            " [0.71394682]] b =  [-20.37490309]\n",
            "step =  32800 error value =  0.16465160372524362 W =  [[1.80309135]\n",
            " [0.7185564 ]] b =  [-20.45821044]\n",
            "step =  33200 error value =  0.1629400491471347 W =  [[1.80922216]\n",
            " [0.72311495]] b =  [-20.54065852]\n",
            "step =  33600 error value =  0.16126325083543303 W =  [[1.81529257]\n",
            " [0.72762358]] b =  [-20.62226466]\n",
            "step =  34000 error value =  0.15962016916767519 W =  [[1.82130375]\n",
            " [0.73208336]] b =  [-20.70304567]\n",
            "step =  34400 error value =  0.1580098053897544 W =  [[1.82725681]\n",
            " [0.73649532]] b =  [-20.78301788]\n",
            "step =  34800 error value =  0.15643119963013086 W =  [[1.83315285]\n",
            " [0.74086044]] b =  [-20.86219711]\n",
            "step =  35200 error value =  0.15488342902887187 W =  [[1.83899295]\n",
            " [0.74517971]] b =  [-20.94059876]\n",
            "step =  35600 error value =  0.15336560597392143 W =  [[1.84477814]\n",
            " [0.74945407]] b =  [-21.01823776]\n",
            "step =  36000 error value =  0.15187687643727277 W =  [[1.85050942]\n",
            " [0.75368441]] b =  [-21.09512864]\n",
            "step =  36400 error value =  0.1504164184047 W =  [[1.85618777]\n",
            " [0.75787163]] b =  [-21.17128549]\n",
            "step =  36800 error value =  0.14898344039272768 W =  [[1.86181415]\n",
            " [0.76201659]] b =  [-21.24672204]\n",
            "step =  37200 error value =  0.14757718004743273 W =  [[1.86738949]\n",
            " [0.76612012]] b =  [-21.32145163]\n",
            "step =  37600 error value =  0.14619690281961184 W =  [[1.8729147 ]\n",
            " [0.77018302]] b =  [-21.39548722]\n",
            "step =  38000 error value =  0.14484190071170586 W =  [[1.87839065]\n",
            " [0.77420609]] b =  [-21.46884143]\n",
            "step =  38400 error value =  0.14351149109181238 W =  [[1.88381819]\n",
            " [0.77819009]] b =  [-21.54152656]\n",
            "step =  38800 error value =  0.14220501557073537 W =  [[1.88919818]\n",
            " [0.78213575]] b =  [-21.61355455]\n",
            "step =  39200 error value =  0.14092183893811855 W =  [[1.89453141]\n",
            " [0.7860438 ]] b =  [-21.68493704]\n",
            "step =  39600 error value =  0.13966134815408068 W =  [[1.89981869]\n",
            " [0.78991494]] b =  [-21.75568537]\n",
            "step =  40000 error value =  0.1384229513930245 W =  [[1.90506079]\n",
            " [0.79374986]] b =  [-21.82581057]\n",
            "step =  40400 error value =  0.13720607713643374 W =  [[1.91025846]\n",
            " [0.79754921]] b =  [-21.89532341]\n",
            "step =  40800 error value =  0.13601017331184453 W =  [[1.91541244]\n",
            " [0.80131365]] b =  [-21.96423436]\n",
            "step =  41200 error value =  0.13483470647514398 W =  [[1.92052345]\n",
            " [0.80504379]] b =  [-22.03255364]\n",
            "step =  41600 error value =  0.13367916103378125 W =  [[1.92559218]\n",
            " [0.80874026]] b =  [-22.10029122]\n",
            "step =  42000 error value =  0.13254303850849877 W =  [[1.93061933]\n",
            " [0.81240365]] b =  [-22.1674568]\n",
            "step =  42400 error value =  0.1314258568312927 W =  [[1.93560555]\n",
            " [0.81603453]] b =  [-22.23405985]\n",
            "step =  42800 error value =  0.13032714967767187 W =  [[1.94055151]\n",
            " [0.81963348]] b =  [-22.30010963]\n",
            "step =  43200 error value =  0.12924646583116223 W =  [[1.94545783]\n",
            " [0.82320104]] b =  [-22.36561514]\n",
            "step =  43600 error value =  0.12818336857827733 W =  [[1.95032515]\n",
            " [0.82673775]] b =  [-22.43058518]\n",
            "step =  44000 error value =  0.12713743513241071 W =  [[1.95515405]\n",
            " [0.83024413]] b =  [-22.49502835]\n",
            "step =  44400 error value =  0.12610825608475326 W =  [[1.95994515]\n",
            " [0.8337207 ]] b =  [-22.55895302]\n",
            "step =  44800 error value =  0.12509543488108918 W =  [[1.96469902]\n",
            " [0.83716795]] b =  [-22.6223674]\n",
            "step =  45200 error value =  0.1240985873228072 W =  [[1.96941622]\n",
            " [0.84058636]] b =  [-22.68527946]\n",
            "step =  45600 error value =  0.12311734109100553 W =  [[1.97409731]\n",
            " [0.84397642]] b =  [-22.74769704]\n",
            "step =  46000 error value =  0.12215133529237118 W =  [[1.97874283]\n",
            " [0.84733857]] b =  [-22.80962774]\n",
            "step =  46400 error value =  0.12120022002564901 W =  [[1.98335331]\n",
            " [0.85067328]] b =  [-22.87107905]\n",
            "step =  46800 error value =  0.12026365596770197 W =  [[1.98792927]\n",
            " [0.85398098]] b =  [-22.93205823]\n",
            "step =  47200 error value =  0.11934131397809007 W =  [[1.99247121]\n",
            " [0.8572621 ]] b =  [-22.99257243]\n",
            "step =  47600 error value =  0.11843287472123591 W =  [[1.99697963]\n",
            " [0.86051706]] b =  [-23.0526286]\n",
            "step =  48000 error value =  0.11753802830520514 W =  [[2.00145502]\n",
            " [0.86374627]] b =  [-23.11223355]\n",
            "step =  48400 error value =  0.11665647393637536 W =  [[2.00589785]\n",
            " [0.86695013]] b =  [-23.17139395]\n",
            "step =  48800 error value =  0.1157879195890519 W =  [[2.01030858]\n",
            " [0.87012903]] b =  [-23.23011631]\n",
            "step =  49200 error value =  0.11493208168940798 W =  [[2.01468767]\n",
            " [0.87328335]] b =  [-23.28840701]\n",
            "step =  49600 error value =  0.11408868481288706 W =  [[2.01903557]\n",
            " [0.87641347]] b =  [-23.34627228]\n",
            "step =  50000 error value =  0.11325746139457914 W =  [[2.0233527 ]\n",
            " [0.87951976]] b =  [-23.40371824]\n",
            "step =  50400 error value =  0.11243815145174951 W =  [[2.02763951]\n",
            " [0.88260256]] b =  [-23.46075084]\n",
            "step =  50800 error value =  0.11163050231808656 W =  [[2.03189639]\n",
            " [0.88566223]] b =  [-23.51737595]\n",
            "step =  51200 error value =  0.11083426838894954 W =  [[2.03612378]\n",
            " [0.8886991 ]] b =  [-23.57359928]\n",
            "step =  51600 error value =  0.1100492108772463 W =  [[2.04032206]\n",
            " [0.89171352]] b =  [-23.62942645]\n",
            "step =  52000 error value =  0.10927509757924801 W =  [[2.04449163]\n",
            " [0.89470581]] b =  [-23.68486294]\n",
            "step =  52400 error value =  0.10851170265007135 W =  [[2.04863287]\n",
            " [0.89767629]] b =  [-23.73991413]\n",
            "step =  52800 error value =  0.10775880638818035 W =  [[2.05274617]\n",
            " [0.90062527]] b =  [-23.7945853]\n",
            "step =  53200 error value =  0.10701619502863702 W =  [[2.05683189]\n",
            " [0.90355306]] b =  [-23.8488816]\n",
            "step =  53600 error value =  0.10628366054455829 W =  [[2.0608904 ]\n",
            " [0.90645995]] b =  [-23.90280809]\n",
            "step =  54000 error value =  0.1055610004565477 W =  [[2.06492205]\n",
            " [0.90934625]] b =  [-23.95636973]\n",
            "step =  54400 error value =  0.10484801764958546 W =  [[2.06892719]\n",
            " [0.91221223]] b =  [-24.00957138]\n",
            "step =  54800 error value =  0.10414452019714304 W =  [[2.07290617]\n",
            " [0.91505819]] b =  [-24.0624178]\n",
            "step =  55200 error value =  0.10345032119215866 W =  [[2.07685931]\n",
            " [0.91788438]] b =  [-24.11491366]\n",
            "step =  55600 error value =  0.10276523858453222 W =  [[2.08078696]\n",
            " [0.9206911 ]] b =  [-24.16706354]\n",
            "step =  56000 error value =  0.10208909502491945 W =  [[2.08468943]\n",
            " [0.92347859]] b =  [-24.21887192]\n",
            "step =  56400 error value =  0.10142171771444049 W =  [[2.08856704]\n",
            " [0.92624712]] b =  [-24.27034322]\n",
            "step =  56800 error value =  0.10076293826018816 W =  [[2.09242011]\n",
            " [0.92899694]] b =  [-24.32148175]\n",
            "step =  57200 error value =  0.10011259253612516 W =  [[2.09624893]\n",
            " [0.9317283 ]] b =  [-24.37229175]\n",
            "step =  57600 error value =  0.09947052054921757 W =  [[2.10005381]\n",
            " [0.93444145]] b =  [-24.42277738]\n",
            "step =  58000 error value =  0.0988365663105981 W =  [[2.10383504]\n",
            " [0.93713663]] b =  [-24.47294271]\n",
            "step =  58400 error value =  0.09821057771147547 W =  [[2.10759291]\n",
            " [0.93981406]] b =  [-24.52279175]\n",
            "step =  58800 error value =  0.09759240640361924 W =  [[2.11132771]\n",
            " [0.94247398]] b =  [-24.57232843]\n",
            "step =  59200 error value =  0.0969819076842325 W =  [[2.11503971]\n",
            " [0.94511662]] b =  [-24.6215566]\n",
            "step =  59600 error value =  0.09637894038504452 W =  [[2.11872918]\n",
            " [0.9477422 ]] b =  [-24.67048006]\n",
            "step =  60000 error value =  0.09578336676536671 W =  [[2.12239641]\n",
            " [0.95035092]] b =  [-24.71910252]\n",
            "step =  60400 error value =  0.09519505240901956 W =  [[2.12604165]\n",
            " [0.95294302]] b =  [-24.76742763]\n",
            "step =  60800 error value =  0.0946138661249777 W =  [[2.12966515]\n",
            " [0.95551869]] b =  [-24.81545897]\n",
            "step =  61200 error value =  0.0940396798514936 W =  [[2.13326718]\n",
            " [0.95807814]] b =  [-24.86320007]\n",
            "step =  61600 error value =  0.09347236856367822 W =  [[2.13684799]\n",
            " [0.96062157]] b =  [-24.91065439]\n",
            "step =  62000 error value =  0.09291181018426732 W =  [[2.14040782]\n",
            " [0.96314918]] b =  [-24.95782531]\n",
            "step =  62400 error value =  0.09235788549754773 W =  [[2.14394691]\n",
            " [0.96566116]] b =  [-25.00471618]\n",
            "step =  62800 error value =  0.09181047806624065 W =  [[2.14746551]\n",
            " [0.96815771]] b =  [-25.05133028]\n",
            "step =  63200 error value =  0.09126947415131416 W =  [[2.15096384]\n",
            " [0.97063901]] b =  [-25.09767083]\n",
            "step =  63600 error value =  0.09073476263448324 W =  [[2.15444214]\n",
            " [0.97310525]] b =  [-25.14374099]\n",
            "step =  64000 error value =  0.0902062349434142 W =  [[2.15790063]\n",
            " [0.9755566 ]] b =  [-25.18954388]\n",
            "step =  64400 error value =  0.0896837849794445 W =  [[2.16133953]\n",
            " [0.97799324]] b =  [-25.23508255]\n",
            "step =  64800 error value =  0.08916730904774137 W =  [[2.16475907]\n",
            " [0.98041535]] b =  [-25.28036002]\n",
            "step =  65200 error value =  0.08865670578981777 W =  [[2.16815945]\n",
            " [0.9828231 ]] b =  [-25.32537924]\n",
            "step =  65600 error value =  0.08815187611830434 W =  [[2.1715409 ]\n",
            " [0.98521665]] b =  [-25.37014311]\n",
            "step =  66000 error value =  0.08765272315388421 W =  [[2.17490361]\n",
            " [0.98759617]] b =  [-25.4146545]\n",
            "step =  66400 error value =  0.08715915216430899 W =  [[2.17824779]\n",
            " [0.98996183]] b =  [-25.45891621]\n",
            "step =  66800 error value =  0.08667107050543224 W =  [[2.18157364]\n",
            " [0.99231378]] b =  [-25.50293101]\n",
            "step =  67200 error value =  0.08618838756416612 W =  [[2.18488137]\n",
            " [0.99465217]] b =  [-25.54670162]\n",
            "step =  67600 error value =  0.08571101470328533 W =  [[2.18817116]\n",
            " [0.99697717]] b =  [-25.59023071]\n",
            "step =  68000 error value =  0.08523886520802422 W =  [[2.19144321]\n",
            " [0.99928893]] b =  [-25.63352091]\n",
            "step =  68400 error value =  0.08477185423439151 W =  [[2.19469771]\n",
            " [1.00158758]] b =  [-25.67657482]\n",
            "step =  68800 error value =  0.08430989875914488 W =  [[2.19793483]\n",
            " [1.00387329]] b =  [-25.71939497]\n",
            "step =  69200 error value =  0.08385291753135976 W =  [[2.20115478]\n",
            " [1.0061462 ]] b =  [-25.76198387]\n",
            "step =  69600 error value =  0.08340083102549872 W =  [[2.20435771]\n",
            " [1.00840643]] b =  [-25.804344]\n",
            "step =  70000 error value =  0.08295356139601136 W =  [[2.20754382]\n",
            " [1.01065415]] b =  [-25.84647777]\n",
            "step =  70400 error value =  0.08251103243334097 W =  [[2.21071328]\n",
            " [1.01288947]] b =  [-25.88838757]\n",
            "step =  70800 error value =  0.08207316952126599 W =  [[2.21386625]\n",
            " [1.01511254]] b =  [-25.93007577]\n",
            "step =  71200 error value =  0.08163989959562012 W =  [[2.21700291]\n",
            " [1.01732349]] b =  [-25.97154466]\n",
            "step =  71600 error value =  0.08121115110425807 W =  [[2.22012343]\n",
            " [1.01952245]] b =  [-26.01279654]\n",
            "step =  72000 error value =  0.08078685396824849 W =  [[2.22322796]\n",
            " [1.02170955]] b =  [-26.05383363]\n",
            "step =  72400 error value =  0.0803669395442706 W =  [[2.22631667]\n",
            " [1.02388492]] b =  [-26.09465816]\n",
            "step =  72800 error value =  0.07995134058813451 W =  [[2.22938973]\n",
            " [1.02604867]] b =  [-26.1352723]\n",
            "step =  73200 error value =  0.079539991219407 W =  [[2.23244727]\n",
            " [1.02820094]] b =  [-26.1756782]\n",
            "step =  73600 error value =  0.0791328268871361 W =  [[2.23548947]\n",
            " [1.03034183]] b =  [-26.21587795]\n",
            "step =  74000 error value =  0.07872978433656011 W =  [[2.23851647]\n",
            " [1.03247148]] b =  [-26.25587364]\n",
            "step =  74400 error value =  0.07833080157683037 W =  [[2.24152842]\n",
            " [1.03459   ]] b =  [-26.29566732]\n",
            "step =  74800 error value =  0.07793581784967255 W =  [[2.24452547]\n",
            " [1.03669749]] b =  [-26.335261]\n",
            "step =  75200 error value =  0.0775447735990237 W =  [[2.24750777]\n",
            " [1.03879409]] b =  [-26.37465667]\n",
            "step =  75600 error value =  0.0771576104414838 W =  [[2.25047545]\n",
            " [1.04087989]] b =  [-26.41385629]\n",
            "step =  76000 error value =  0.07677427113769397 W =  [[2.25342867]\n",
            " [1.042955  ]] b =  [-26.45286178]\n",
            "step =  76400 error value =  0.07639469956453661 W =  [[2.25636755]\n",
            " [1.04501955]] b =  [-26.49167505]\n",
            "step =  76800 error value =  0.07601884068812721 W =  [[2.25929224]\n",
            " [1.04707362]] b =  [-26.53029797]\n",
            "step =  77200 error value =  0.07564664053756417 W =  [[2.26220287]\n",
            " [1.04911733]] b =  [-26.56873238]\n",
            "step =  77600 error value =  0.07527804617948959 W =  [[2.26509958]\n",
            " [1.05115078]] b =  [-26.60698011]\n",
            "step =  78000 error value =  0.07491300569331277 W =  [[2.2679825 ]\n",
            " [1.05317407]] b =  [-26.64504294]\n",
            "step =  78400 error value =  0.07455146814720685 W =  [[2.27085175]\n",
            " [1.05518731]] b =  [-26.68292265]\n",
            "step =  78800 error value =  0.07419338357471007 W =  [[2.27370747]\n",
            " [1.05719058]] b =  [-26.72062098]\n",
            "step =  79200 error value =  0.07383870295204188 W =  [[2.27654978]\n",
            " [1.05918399]] b =  [-26.75813964]\n",
            "step =  79600 error value =  0.07348737817601884 W =  [[2.27937881]\n",
            " [1.06116764]] b =  [-26.79548033]\n",
            "step =  80000 error value =  0.07313936204262575 W =  [[2.28219468]\n",
            " [1.06314161]] b =  [-26.83264471]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3bJKAGeDrPm",
        "outputId": "980d47bf-b2f7-477f-810f-f00898f3c994"
      },
      "source": [
        "test_data = np.array([3, 17])\n",
        "\n",
        "print(predict(test_data))\n",
        "\n",
        "test_data = np.array([5, 8])\n",
        "\n",
        "print(predict(test_data))\n",
        "\n",
        "test_data = np.array([7, 21])\n",
        "\n",
        "print(predict(test_data))\n",
        "\n",
        "test_data = np.array([12, 0])\n",
        "\n",
        "print(predict(test_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([0.12868307]), 0)\n",
            "(array([0.00099027]), 0)\n",
            "(array([0.99998955]), 1)\n",
            "(array([0.6349916]), 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTTpqRqaMMJX"
      },
      "source": [
        "# **Machine Learning XOR Problem**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6eF20SIawOs"
      },
      "source": [
        "Gate Class "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NM1Vxozvav7D"
      },
      "source": [
        "class LogicGate:\n",
        "  def __init__(self, gate_name, xdata, tdata):\n",
        "    self.name = gate_name\n",
        "\n",
        "    self.__xdata = xdata.reshape(4,2)\n",
        "    self.__tdata = tdata.reshape(4,1)\n",
        "\n",
        "    self.__W = np.random.rand(2,1)\n",
        "    self.__b = np.random.rand(1)\n",
        "\n",
        "    self.__learning_rate = 1e-2\n",
        "\n",
        "  def __loss_func(self):\n",
        "    delta = 1e-7\n",
        "\n",
        "    z = np.dot(self.__xdata, self.__W) + self.__b\n",
        "    y = sigmoid(z)\n",
        "\n",
        "    return -np.sum(self.__tdata * np.log(y + delta) + (1 - self.__tdata)*np.log((1 - y) + delta))\n",
        "\n",
        "  def error_val(self):\n",
        "    delta = 1e-7\n",
        "\n",
        "    z = np.dot(self.__xdata, self.__W) + self.__b\n",
        "    y = sigmoid(z)\n",
        "\n",
        "    return -np.sum(self.__tdata * np.log(y + delta) + (1 - self.__tdata)*np.log((1 - y) + delta))\n",
        "\n",
        "  def train(self):\n",
        "    f = lambda x : self.__loss_func()\n",
        "\n",
        "    print(\"Initial error value = \", self.error_val())\n",
        "\n",
        "    for step in range(8001):\n",
        "\n",
        "      self.__W -= self.__learning_rate * numerical_derivative(f, self.__W)\n",
        "\n",
        "      self.__b -= self.__learning_rate * numerical_derivative(f, self.__b)\n",
        "\n",
        "      if(step % 400 == 0):\n",
        "        print(\"step = \", step, \"error value = \", self.error_val(), \" W = \", self.__W, \" b = \", self.__b)\n",
        "\n",
        "\n",
        "  def predict(self, input_data):\n",
        "    z = np.dot(input_data, self.__W) + self.__b\n",
        "    y = sigmoid(z)\n",
        "\n",
        "    if y > 0.5: result = 1\n",
        "    else: result = 0\n",
        "\n",
        "    return y, result\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8GT4XTajAOV"
      },
      "source": [
        "AND GATE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGa1ugUZaigc",
        "outputId": "be7e343f-c8e8-4b15-c254-6c923cbebcca"
      },
      "source": [
        "xdata = np.array([[0,0], [0,1],[1,0],[1,1]])\n",
        "tdata = np.array([0,0,0,1])\n",
        "\n",
        "AND_obj = LogicGate(\"AND_GATE\", xdata, tdata)\n",
        "\n",
        "AND_obj.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial error value =  4.077746819217756\n",
            "step =  0 error value =  4.034906941529735  W =  [[0.13806487]\n",
            " [0.35592748]]  b =  [0.76057495]\n",
            "step =  400 error value =  1.6380175587137926  W =  [[0.72158722]\n",
            " [0.80909367]]  b =  [-1.58348991]\n",
            "step =  800 error value =  1.193435315140189  W =  [[1.42840842]\n",
            " [1.46734658]]  b =  [-2.49618219]\n",
            "step =  1200 error value =  0.9501239242287737  W =  [[1.93390072]\n",
            " [1.95263925]]  b =  [-3.18928175]\n",
            "step =  1600 error value =  0.7926080110431439  W =  [[2.33275236]\n",
            " [2.34242753]]  b =  [-3.75409133]\n",
            "step =  2000 error value =  0.680697636466389  W =  [[2.66529168]\n",
            " [2.67060155]]  b =  [-4.23331815]\n",
            "step =  2400 error value =  0.596494657833529  W =  [[2.95189101]\n",
            " [2.95496212]]  b =  [-4.65061935]\n",
            "step =  2800 error value =  0.5306240917113841  W =  [[3.20436068]\n",
            " [3.20621899]]  b =  [-5.02062445]\n",
            "step =  3200 error value =  0.4776105925777948  W =  [[3.43025343]\n",
            " [3.43142265]]  b =  [-5.35312411]\n",
            "step =  3600 error value =  0.4340029394935403  W =  [[3.6347515 ]\n",
            " [3.63551256]]  b =  [-5.65505559]\n",
            "step =  4000 error value =  0.3975008996059343  W =  [[3.82159835]\n",
            " [3.82210867]]  b =  [-5.93154663]\n",
            "step =  4400 error value =  0.3665048313380103  W =  [[3.99360446]\n",
            " [3.99395571]]  b =  [-6.18651175]\n",
            "step =  4800 error value =  0.3398644444274085  W =  [[4.15294339]\n",
            " [4.15319082]]  b =  [-6.42301602]\n",
            "step =  5200 error value =  0.3167298294828277  W =  [[4.30133611]\n",
            " [4.30151405]]  b =  [-6.64350901]\n",
            "step =  5600 error value =  0.2964587192626328  W =  [[4.44017145]\n",
            " [4.44030179]]  b =  [-6.84998177]\n",
            "step =  6000 error value =  0.27855642155021193  W =  [[4.57058799]\n",
            " [4.57068507]]  b =  [-7.04407585]\n",
            "step =  6400 error value =  0.2626356133814958  W =  [[4.69353172]\n",
            " [4.69360511]]  b =  [-7.22716127]\n",
            "step =  6800 error value =  0.2483886729657139  W =  [[4.80979763]\n",
            " [4.80985388]]  b =  [-7.40039363]\n",
            "step =  7200 error value =  0.23556818238423433  W =  [[4.92006052]\n",
            " [4.92010417]]  b =  [-7.56475674]\n",
            "step =  7600 error value =  0.22397290247858226  W =  [[5.02489822]\n",
            " [5.02493248]]  b =  [-7.72109518]\n",
            "step =  8000 error value =  0.21343750034534506  W =  [[5.12480937]\n",
            " [5.12483654]]  b =  [-7.87013934]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QEVuWv-DrSK",
        "outputId": "ea27142b-f1bb-4841-ff42-11030d450f86"
      },
      "source": [
        "print(AND_obj.name, '\\n')\n",
        "\n",
        "test_data = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "\n",
        "for input_data in test_data:\n",
        "  (sigmoid_val, logical_val) = AND_obj.predict(input_data)\n",
        "  print(input_data, \" = \", logical_val, \"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AND_GATE \n",
            "\n",
            "[0 0]  =  0 \n",
            "\n",
            "[0 1]  =  0 \n",
            "\n",
            "[1 0]  =  0 \n",
            "\n",
            "[1 1]  =  1 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drKFxOYMhddz"
      },
      "source": [
        "OR GATE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRXdUC2MMTJ_",
        "outputId": "4b5e5779-7b63-4584-f020-31166fd76eda"
      },
      "source": [
        "xdata = np.array([[0,0], [0,1],[1,0],[1,1]])\n",
        "tdata = np.array([0,1,1,1])\n",
        "\n",
        "OR_obj = LogicGate(\"OR_GATE\", xdata, tdata)\n",
        "\n",
        "OR_obj.train()\n",
        "\n",
        "print(OR_obj.name, '\\n')\n",
        "\n",
        "test_data = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "\n",
        "for input_data in test_data:\n",
        "  (sigmoid_val, logical_val) = OR_obj.predict(input_data)\n",
        "  print(input_data, \" = \", logical_val, \"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial error value =  1.6551931737976397\n",
            "step =  0 error value =  1.652963339516028  W =  [[0.71878936]\n",
            " [0.96770009]]  b =  [0.94198679]\n",
            "step =  400 error value =  1.0717345619022527  W =  [[1.60483611]\n",
            " [1.75122904]]  b =  [0.00768689]\n",
            "step =  800 error value =  0.7824231987219963  W =  [[2.30646826]\n",
            " [2.39546966]]  b =  [-0.48469458]\n",
            "step =  1200 error value =  0.6108090985427186  W =  [[2.85563708]\n",
            " [2.91342639]]  b =  [-0.82251019]\n",
            "step =  1600 error value =  0.4981129881942807  W =  [[3.3022152 ]\n",
            " [3.34200217]]  b =  [-1.08064814]\n",
            "step =  2000 error value =  0.4189066097413615  W =  [[3.6768756 ]\n",
            " [3.70560962]]  b =  [-1.28979266]\n",
            "step =  2400 error value =  0.3604613123782732  W =  [[3.99872445]\n",
            " [4.02029109]]  b =  [-1.46558421]\n",
            "step =  2800 error value =  0.3157179202863021  W =  [[4.28030221]\n",
            " [4.29700285]]  b =  [-1.61713023]\n",
            "step =  3200 error value =  0.28045860226811253  W =  [[4.53023698]\n",
            " [4.54350509]]  b =  [-1.75023058]\n",
            "step =  3600 error value =  0.25201587239080725  W =  [[4.75469983]\n",
            " [4.76546762]]  b =  [-1.86882026]\n",
            "step =  4000 error value =  0.22862498491842975  W =  [[4.9582471 ]\n",
            " [4.96714351]]  b =  [-1.9756972]\n",
            "step =  4400 error value =  0.2090746790431823  W =  [[5.14433285]\n",
            " [5.15179583]]  b =  [-2.0729239]\n",
            "step =  4800 error value =  0.1925076680169356  W =  [[5.31563438]\n",
            " [5.3219773 ]]  b =  [-2.16206507]\n",
            "step =  5200 error value =  0.17830117496440362  W =  [[5.47426657]\n",
            " [5.47971903]]  b =  [-2.24433599]\n",
            "step =  5600 error value =  0.16599252348478366  W =  [[5.62192758]\n",
            " [5.62666133]]  b =  [-2.32069921]\n",
            "step =  6000 error value =  0.15523120749873212  W =  [[5.76000056]\n",
            " [5.76414641]]  b =  [-2.39192996]\n",
            "step =  6400 error value =  0.14574710761382048  W =  [[5.88962624]\n",
            " [5.8932855 ]]  b =  [-2.45866165]\n",
            "step =  6800 error value =  0.13732887248587475  W =  [[6.01175598]\n",
            " [6.01500821]]  b =  [-2.52141829]\n",
            "step =  7200 error value =  0.12980888081520237  W =  [[6.12719109]\n",
            " [6.1300996 ]]  b =  [-2.58063826]\n",
            "step =  7600 error value =  0.12305257006087993  W =  [[6.23661252]\n",
            " [6.23922829]]  b =  [-2.63669187]\n",
            "step =  8000 error value =  0.11695072728118458  W =  [[6.34060366]\n",
            " [6.34296816]]  b =  [-2.68989472]\n",
            "OR_GATE \n",
            "\n",
            "[0 0]  =  0 \n",
            "\n",
            "[0 1]  =  1 \n",
            "\n",
            "[1 0]  =  1 \n",
            "\n",
            "[1 1]  =  1 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTY9M_9ijM1G"
      },
      "source": [
        "NAND GATE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCouLlGeMTMH",
        "outputId": "d845c75d-f2b7-41d4-a554-1071199d6049"
      },
      "source": [
        "xdata = np.array([[0,0], [0,1],[1,0],[1,1]])\n",
        "tdata = np.array([1,1,1,0])\n",
        "\n",
        "NAND_obj = LogicGate(\"NAND_GATE\", xdata, tdata)\n",
        "\n",
        "NAND_obj.train()\n",
        "\n",
        "print(NAND_obj.name, '\\n')\n",
        "\n",
        "test_data = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "\n",
        "for input_data in test_data:\n",
        "  (sigmoid_val, logical_val) = NAND_obj.predict(input_data)\n",
        "  print(input_data, \" = \", logical_val, \"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial error value =  2.8179561210347774\n",
            "step =  0 error value =  2.81152785896797  W =  [[0.81191909]\n",
            " [0.17807282]]  b =  [0.55305314]\n",
            "step =  400 error value =  1.6310731730834644  W =  [[-0.64121084]\n",
            " [-0.91087013]]  b =  [1.60581019]\n",
            "step =  800 error value =  1.1888023072459686  W =  [[-1.39711724]\n",
            " [-1.51738374]]  b =  [2.50963446]\n",
            "step =  1200 error value =  0.9470206938142207  W =  [[-1.92165835]\n",
            " [-1.97961578]]  b =  [3.19988907]\n",
            "step =  1600 error value =  0.7904150170573181  W =  [[-2.32870434]\n",
            " [-2.35866356]]  b =  [3.76293136]\n",
            "step =  2000 error value =  0.6790687197728777  W =  [[-2.66493056]\n",
            " [-2.6813886 ]]  b =  [4.24092879]\n",
            "step =  2400 error value =  0.5952363053191737  W =  [[-2.95322627]\n",
            " [-2.96275315]]  b =  [4.65731397]\n",
            "step =  2800 error value =  0.5296221789056373  W =  [[-3.20646686]\n",
            " [-3.21223565]]  b =  [5.02660476]\n",
            "step =  3200 error value =  0.47679378606348366  W =  [[-3.43268286]\n",
            " [-3.43631475]]  b =  [5.35852927]\n",
            "step =  3600 error value =  0.4333243186100964  W =  [[-3.63728193]\n",
            " [-3.63964725]]  b =  [5.6599865]\n",
            "step =  4000 error value =  0.39692826854192925  W =  [[-3.82411845]\n",
            " [-3.82570524]]  b =  [5.93607922]\n",
            "step =  4400 error value =  0.36601531893708406  W =  [[-3.99605928]\n",
            " [-3.99715193]]  b =  [6.1907048]\n",
            "step =  4800 error value =  0.3394413322814581  W =  [[-4.15530739]\n",
            " [-4.15607738]]  b =  [6.42691608]\n",
            "step =  5200 error value =  0.31636060129058835  W =  [[-4.30359931]\n",
            " [-4.3041532 ]]  b =  [6.64715363]\n",
            "step =  5600 error value =  0.29613381305256586  W =  [[-4.44233206]\n",
            " [-4.44273791]]  b =  [6.85340171]\n",
            "step =  6000 error value =  0.2782684042365165  W =  [[-4.57264852]\n",
            " [-4.57295087]]  b =  [7.04729665]\n",
            "step =  6400 error value =  0.2623786187740128  W =  [[-4.6954968 ]\n",
            " [-4.69572544]]  b =  [7.23020435]\n",
            "step =  6800 error value =  0.24815800954086537  W =  [[-4.81167281]\n",
            " [-4.81184809]]  b =  [7.40327716]\n",
            "step =  7200 error value =  0.23536005356809098  W =  [[-4.92185165]\n",
            " [-4.92198769]]  b =  [7.56749626]\n",
            "step =  7600 error value =  0.22378420335567048  W =  [[-5.02661104]\n",
            " [-5.02671783]]  b =  [7.72370408]\n",
            "step =  8000 error value =  0.2132656674151006  W =  [[-5.12644936]\n",
            " [-5.12653407]]  b =  [7.87262925]\n",
            "NAND_GATE \n",
            "\n",
            "[0 0]  =  1 \n",
            "\n",
            "[0 1]  =  1 \n",
            "\n",
            "[1 0]  =  1 \n",
            "\n",
            "[1 1]  =  0 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rxlILirjWol"
      },
      "source": [
        "<h3>XOR GATE 1</h3><br>\n",
        "=> Linear한 선을 그려서는 XOR을 전부 충족할 수 없고 절반만 충족함\n",
        "\n",
        "<img src=\"https://t1.daumcdn.net/cfile/tistory/99612E4B5C0B73DD34?download\">\n",
        "\n",
        "[ 출처 : https://trendy00develope.tistory.com/35 ]\n",
        "\n",
        "\n",
        "해결 방법 1 : 레이어를 Deep하게 쌓는다.\n",
        "\n",
        "해결 방법 2 : NAND, OR, AND 게이트를 이용한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQACSabYMTOh",
        "outputId": "9157e220-250e-4973-f829-7b2b05c5455e"
      },
      "source": [
        "xdata = np.array([[0,0], [0,1],[1,0],[1,1]])\n",
        "tdata = np.array([0,1,1,0])\n",
        "\n",
        "XOR_obj = LogicGate(\"XOR_GATE\", xdata, tdata)\n",
        "\n",
        "XOR_obj.train()\n",
        "\n",
        "print(XOR_obj.name, '\\n')\n",
        "\n",
        "test_data = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "\n",
        "for input_data in test_data:\n",
        "  (sigmoid_val, logical_val) = XOR_obj.predict(input_data)\n",
        "  print(input_data, \" = \", logical_val, \"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial error value =  3.2156363181011063\n",
            "step =  0 error value =  3.205279273797954  W =  [[0.94183138]\n",
            " [0.58149682]]  b =  [0.02638807]\n",
            "step =  400 error value =  2.7885889881128336  W =  [[0.30389175]\n",
            " [0.16986146]]  b =  [-0.27907417]\n",
            "step =  800 error value =  2.7769800444735537  W =  [[0.15066846]\n",
            " [0.10140189]]  b =  [-0.14937628]\n",
            "step =  1200 error value =  2.7738121856041  W =  [[0.07618824]\n",
            " [0.05808495]]  b =  [-0.07956291]\n",
            "step =  1600 error value =  2.77293202228317  W =  [[0.03907351]\n",
            " [0.03242185]]  b =  [-0.04236301]\n",
            "step =  2000 error value =  2.7726850499747853  W =  [[0.02025401]\n",
            " [0.01781004]]  b =  [-0.02255385]\n",
            "step =  2400 error value =  2.7726153959963216  W =  [[0.01058127]\n",
            " [0.00968331]]  b =  [-0.01200722]\n",
            "step =  2800 error value =  2.772595701512968  W =  [[0.00555915]\n",
            " [0.00522923]]  b =  [-0.00639235]\n",
            "step =  3200 error value =  2.7725901260551478  W =  [[0.00293234]\n",
            " [0.00281112]]  b =  [-0.00340313]\n",
            "step =  3600 error value =  2.772588546714202  W =  [[0.0015511 ]\n",
            " [0.00150657]]  b =  [-0.00181174]\n",
            "step =  4000 error value =  2.7725880992113803  W =  [[0.00082209]\n",
            " [0.00080573]]  b =  [-0.00096452]\n",
            "step =  4400 error value =  2.772587972395034  W =  [[0.00043631]\n",
            " [0.0004303 ]]  b =  [-0.00051349]\n",
            "step =  4800 error value =  2.772587936454615  W =  [[0.00023179]\n",
            " [0.00022958]]  b =  [-0.00027337]\n",
            "step =  5200 error value =  2.7725879262685926  W =  [[0.00012321]\n",
            " [0.0001224 ]]  b =  [-0.00014553]\n",
            "step =  5600 error value =  2.7725879233816872  W =  [[6.55291665e-05]\n",
            " [6.52309346e-05]]  b =  [-7.74782173e-05]\n",
            "step =  6000 error value =  2.772587922563479  W =  [[3.48614339e-05]\n",
            " [3.47518576e-05]]  b =  [-4.12473963e-05]\n",
            "step =  6400 error value =  2.7725879223315815  W =  [[1.85502866e-05]\n",
            " [1.85100263e-05]]  b =  [-2.19590453e-05]\n",
            "step =  6800 error value =  2.772587922265857  W =  [[9.87237178e-06]\n",
            " [9.85757942e-06]]  b =  [-1.16904272e-05]\n",
            "step =  7200 error value =  2.7725879222472294  W =  [[5.25457484e-06]\n",
            " [5.24914022e-06]]  b =  [-6.22368081e-06]\n",
            "step =  7600 error value =  2.7725879222419496  W =  [[2.79695145e-06]\n",
            " [2.79495498e-06]]  b =  [-3.31332683e-06]\n",
            "step =  8000 error value =  2.7725879222404535  W =  [[1.48886001e-06]\n",
            " [1.48812660e-06]]  b =  [-1.76392949e-06]\n",
            "XOR_GATE \n",
            "\n",
            "[0 0]  =  0 \n",
            "\n",
            "[0 1]  =  0 \n",
            "\n",
            "[1 0]  =  0 \n",
            "\n",
            "[1 1]  =  1 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwOe6HmbkN19"
      },
      "source": [
        "XOR GATE 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xj0SsHSJkNsf",
        "outputId": "04b321ca-4207-490c-ef03-8fe38573743b"
      },
      "source": [
        "input_data = np.array([[0,0], [0,1],[1,0],[1,1]])\n",
        "\n",
        "s1 = [] # NAND 출력\n",
        "s2 = [] # OR 출력\n",
        "\n",
        "new_input_data = [] # AND 입력\n",
        "final_output = [] # AND 출력\n",
        "\n",
        "for index in range(len(input_data)):\n",
        "\n",
        "  s1 = NAND_obj.predict(input_data[index])\n",
        "  s2 = OR_obj.predict(input_data[index])\n",
        "  \n",
        "  new_input_data.append(s1[-1])\n",
        "  new_input_data.append(s2[-1])\n",
        "\n",
        "  (sigmoid_val, logical_val) = AND_obj.predict(np.array(new_input_data))\n",
        "\n",
        "  final_output.append(logical_val)\n",
        "  new_input_data = []\n",
        "\n",
        "for index in range(len(input_data)):\n",
        "  print(input_data[index], \" = \", final_output[index], end='')\n",
        "  print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0]  =  0\n",
            "\n",
            "[0 1]  =  1\n",
            "\n",
            "[1 0]  =  1\n",
            "\n",
            "[1 1]  =  0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qD-6uITPo4D2"
      },
      "source": [
        "<h1>Deep Learning</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uwup-zv2rkEH"
      },
      "source": [
        "XOR 문제 해결"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yz7QNtORMTQs"
      },
      "source": [
        "class LogicGate:\n",
        "  def __init__(self, gate_name, xdata, tdata):\n",
        "    self.name = gate_name\n",
        "\n",
        "    self.__xdata = xdata.reshape(4,2)\n",
        "    self.__tdata = tdata.reshape(4,1)\n",
        "\n",
        "    self.__W2 = np.random.rand(2,6)\n",
        "    self.__b2 = np.random.rand(6)\n",
        "\n",
        "    self.__W3 = np.random.rand(6,1)\n",
        "    self.__b3 = np.random.rand(1)\n",
        "\n",
        "    self.__learning_rate = 1e-2\n",
        "\n",
        "\n",
        "  def feed_forward(self):\n",
        "    delta = 1e-7\n",
        "\n",
        "    z2 = np.dot(self.__xdata, self.__W2) + self.__b2\n",
        "    a2 = sigmoid(z2)\n",
        "\n",
        "    z3 = np.dot(a2, self.__W3) + self.__b3\n",
        "    y = a3 = sigmoid(z3)\n",
        "\n",
        "    return -np.sum(self.__tdata * np.log(y + delta) + (1 - self.__tdata)*np.log((1 - y) + delta))\n",
        "\n",
        "  def loss_func(self):\n",
        "    delta = 1e-7\n",
        "\n",
        "    z2 = np.dot(self.__xdata, self.__W2) + self.__b2\n",
        "    a2 = sigmoid(z2)\n",
        "\n",
        "    z3 = np.dot(a2, self.__W3) + self.__b3\n",
        "    y = a3 = sigmoid(z3)\n",
        "\n",
        "    return -np.sum(self.__tdata * np.log(y + delta) + (1 - self.__tdata)*np.log((1 - y) + delta))\n",
        "\n",
        "  def train(self):\n",
        "    f = lambda x : self.loss_func()\n",
        "\n",
        "    print(\"Initial error value = \", self.feed_forward())\n",
        "\n",
        "    for step in range(10001):\n",
        "\n",
        "      self.__W2 -= self.__learning_rate * numerical_derivative(f, self.__W2)\n",
        "\n",
        "      self.__b2 -= self.__learning_rate * numerical_derivative(f, self.__b2)\n",
        "\n",
        "      self.__W3 -= self.__learning_rate * numerical_derivative(f, self.__W3)\n",
        "\n",
        "      self.__b3 -= self.__learning_rate * numerical_derivative(f, self.__b3)\n",
        "\n",
        "      if(step % 400 == 0):\n",
        "        print(\"step = \", step, \"error value = \", self.loss_func())\n",
        "\n",
        "\n",
        "  def predict(self, input_data):\n",
        "\n",
        "    z2 = np.dot(input_data, self.__W2) + self.__b2\n",
        "    a2 = sigmoid(z2)\n",
        "\n",
        "    z3 = np.dot(a2, self.__W3) + self.__b3\n",
        "    y = a3 = sigmoid(z3)\n",
        "\n",
        "    if y > 0.5: result = 1\n",
        "    else: result = 0\n",
        "\n",
        "    return y, result\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeCRzfgSMTTF",
        "outputId": "cfb4c1bb-9d50-47f1-f6ed-4269d301377d"
      },
      "source": [
        "xdata = np.array([[0,0], [0,1],[1,0],[1,1]])\n",
        "tdata = np.array([0,1,1,0])\n",
        "\n",
        "XOR_obj = LogicGate(\"XOR_GATE\", xdata, tdata)\n",
        "\n",
        "XOR_obj.train()\n",
        "\n",
        "print(XOR_obj.name, '\\n')\n",
        "\n",
        "test_data = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "\n",
        "for input_data in test_data:\n",
        "  (sigmoid_val, logical_val) = XOR_obj.predict(input_data)\n",
        "  print(input_data, \" = \", logical_val, \"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial error value =  4.7876202317284555\n",
            "step =  0 error value =  4.690502568886616\n",
            "step =  400 error value =  2.773333504231356\n",
            "step =  800 error value =  2.7715196323202558\n",
            "step =  1200 error value =  2.769752489434355\n",
            "step =  1600 error value =  2.7679026473237176\n",
            "step =  2000 error value =  2.7658359019082317\n",
            "step =  2400 error value =  2.7633937224316028\n",
            "step =  2800 error value =  2.760369960268089\n",
            "step =  3200 error value =  2.7564791964262008\n",
            "step =  3600 error value =  2.751311268811511\n",
            "step =  4000 error value =  2.744265824166166\n",
            "step =  4400 error value =  2.7344613170274554\n",
            "step =  4800 error value =  2.72061533117345\n",
            "step =  5200 error value =  2.700894718659558\n",
            "step =  5600 error value =  2.67272991595714\n",
            "step =  6000 error value =  2.632595411298812\n",
            "step =  6400 error value =  2.5758638925956077\n",
            "step =  6800 error value =  2.4971369362854356\n",
            "step =  7200 error value =  2.391642016655775\n",
            "step =  7600 error value =  2.2573877767310595\n",
            "step =  8000 error value =  2.0959702108221263\n",
            "step =  8400 error value =  1.910877779989428\n",
            "step =  8800 error value =  1.7066017563575935\n",
            "step =  9200 error value =  1.4914977775526994\n",
            "step =  9600 error value =  1.279510385816916\n",
            "step =  10000 error value =  1.0853933224294363\n",
            "XOR_GATE \n",
            "\n",
            "[0 0]  =  0 \n",
            "\n",
            "[0 1]  =  1 \n",
            "\n",
            "[1 0]  =  1 \n",
            "\n",
            "[1 1]  =  0 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WM4VAvU5wwYD"
      },
      "source": [
        "<h1>MNIST (필기체숫자) 인식</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37J77D1hMTVS"
      },
      "source": [
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnZ4MA9KMTXe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e481e40-1f7f-4954-cfef-d75e4da5a72a"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxilFxuiMTZ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9735231d-f861-48c6-fab2-28f16228c4ec"
      },
      "source": [
        "train_data_name = \"/content/drive/MyDrive/mnist datas/mnist_train.csv\"\n",
        "test_data_name = \"/content/drive/MyDrive/mnist datas/mnist_test.csv\"\n",
        "\n",
        "training_data = np.loadtxt(train_data_name, delimiter=',',dtype=np.float32)\n",
        "test_data = np.loadtxt(test_data_name, delimiter=',', dtype=np.float32)\n",
        "\n",
        "print(\"training_data.shape = \", training_data.shape, \", test_data.shape\", test_data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training_data.shape =  (60000, 785) , test_data.shape (10000, 785)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hygAL_99nzJF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "b498f57e-89a4-4d3d-f81e-86b1c16d67ef"
      },
      "source": [
        "img = training_data[0][1:].reshape(28, 28)\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_UziO6tnzb0"
      },
      "source": [
        "class NeuralNetwork:\n",
        "\n",
        "  def __init__(self, input_nodes, hidden_nodes, output_nodes):\n",
        "\n",
        "    self.input_nodes = input_nodes\n",
        "    self.hidden_nodes = hidden_nodes\n",
        "    self.output_nodes = output_nodes\n",
        "\n",
        "    self.W2 = np.random.rand(self.input_nodes, self.hidden_nodes)\n",
        "    self.b2 = np.random.rand(self.hidden_nodes)\n",
        "\n",
        "    self.W3 = np.random.rand(self.hidden_nodes, self.output_nodes)\n",
        "    self.b3 = np.random.rand(self.output_nodes)\n",
        "\n",
        "    self.learning_rate = 1e-4\n",
        "\n",
        "\n",
        "  def feed_forward(self):\n",
        "    delta = 1e-7\n",
        "\n",
        "    z1 = np.dot(self.input_data, self.W2) + self.b2\n",
        "    a1 = sigmoid(z1)\n",
        "\n",
        "    z2 = np.dot(a1, self.W3) + self.b3\n",
        "    y = sigmoid(z2)\n",
        "\n",
        "    return -np.sum(self.target_data * np.log(y + delta) + (1 - self.target_data)*np.log((1 - y) + delta))\n",
        "\n",
        "  def train(self, training_data):\n",
        "\n",
        "    self.target_data = np.zeros(output_nodes) + 0.01\n",
        "    self.target_data[int(training_data[0])] = 0.99\n",
        "\n",
        "    self.input_data = (training_data[1:] / 255.0 * 0.99) + 0.01\n",
        "\n",
        "    f = lambda x : self.feed_forward()\n",
        "\n",
        "    self.W2 -= self.learning_rate * numerical_derivative(f, self.W2)\n",
        "\n",
        "    self.b2 -= self.learning_rate * numerical_derivative(f, self.b2)\n",
        "\n",
        "    self.W3 -= self.learning_rate * numerical_derivative(f, self.W3)\n",
        "\n",
        "    self.b3 -= self.learning_rate * numerical_derivative(f, self.b3)\n",
        "\n",
        "  def predict(self, input_data):\n",
        "\n",
        "    z2 = np.dot(input_data, self.W2) + self.b2\n",
        "    a2 = sigmoid(z2)\n",
        "\n",
        "    z3 = np.dot(a2, self.W3) + self.b3\n",
        "    y = sigmoid(z3)\n",
        "\n",
        "    predicted_num = np.argmax(y)\n",
        "\n",
        "    return predicted_num\n",
        "\n",
        "  def accuracy(self, test_data):\n",
        "    matched_list = []\n",
        "    not_matched_list = []\n",
        "\n",
        "    for index in range(len(test_data)):\n",
        "      label = int(test_data[index, 0])\n",
        "\n",
        "      data = (test_data[index, 1:] / 255.0 * 0.99) + 0.01\n",
        "\n",
        "      predicted_num = self.predict(data)\n",
        "\n",
        "      if label == predicted_num:\n",
        "        matched_list.append(index)\n",
        "      else:\n",
        "        not_matched_list.append(index)\n",
        "\n",
        "    print(\"Current Accuracy = \", 100*(len(matched_list)/(len(test_data))), \" %\")\n",
        "\n",
        "    return matched_list, not_matched_list\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctLyC_bCnzet",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "17764382-188b-4c16-996e-98ebf870929e"
      },
      "source": [
        "input_nodes = 784\n",
        "hidden_nodes = 100\n",
        "output_nodes = 10\n",
        "\n",
        "nn = NeuralNetwork(input_nodes, hidden_nodes, output_nodes)\n",
        "\n",
        "for step in range(30001):\n",
        "  index = np.random.randint(0, len(training_data) - 1)\n",
        "  \n",
        "  nn.train(training_data[index])\n",
        "\n",
        "  if step % 400 == 0:\n",
        "    print(\"step = \", step, \", loss_val = \", nn.feed_forward())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step =  0 , loss_val =  143.77341309854825\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-61ce70eb2712>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m400\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-f9130a4a628c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, training_data)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW2\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnumerical_derivative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb2\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnumerical_derivative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-0dd9251d1230>\u001b[0m in \u001b[0;36mnumerical_derivative\u001b[0;34m(f, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtmp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_val\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdelta_x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mfx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_val\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdelta_x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-f9130a4a628c>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.99\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW2\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnumerical_derivative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-f9130a4a628c>\u001b[0m in \u001b[0;36mfeed_forward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1B8xDYpz0l0q"
      },
      "source": [
        "<h1>오차역전파</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhcqFqxCsLW5"
      },
      "source": [
        "수치미분을 통해서 가중치와 바이어스 업데이트 시에는 많은 시간이 소요 된다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqHueNrq1b7V"
      },
      "source": [
        "오차역전파 공식을 통해서 가중치와 바이어스를 수치미분 공식을 이용하지 않고 곱의 형태로 나타내서 속도를 향상할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3Vp8WKk_NI0"
      },
      "source": [
        "따라서 오차역전파 공식을 이용해 위의 MNIST 모델을 더 빠르게 학습할 수 있도록 리모델링 하겠다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahcSRANYsIGR"
      },
      "source": [
        "from datetime import datetime\n",
        "\n",
        "class NeuralNetwork:\n",
        "\n",
        "  def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
        "\n",
        "    self.input_nodes = input_nodes\n",
        "    self.hidden_nodes = hidden_nodes\n",
        "    self.output_nodes = output_nodes\n",
        "\n",
        "    self.W2 = np.random.rand(self.input_nodes, self.hidden_nodes) / np.sqrt(self.input_nodes/2)\n",
        "    self.b2 = np.random.rand(self.hidden_nodes)\n",
        "\n",
        "    self.W3 = np.random.rand(self.hidden_nodes, self.output_nodes) / np.sqrt(self.hidden_nodes/2)\n",
        "    self.b3 = np.random.rand(self.output_nodes)\n",
        "\n",
        "    self.Z3 = np.zeros([1, output_nodes])\n",
        "    self.A3 = np.zeros([1, output_nodes])\n",
        "\n",
        "    self.Z2 = np.zeros([1, hidden_nodes])\n",
        "    self.A2 = np.zeros([1, hidden_nodes])\n",
        "\n",
        "    self.Z1 = np.zeros([1, input_nodes])\n",
        "    self.A1 = np.zeros([1, input_nodes])\n",
        "\n",
        "    self.learning_rate = learning_rate\n",
        "\n",
        "\n",
        "  def feed_forward(self):\n",
        "    delta = 1e-7\n",
        "\n",
        "    self.Z1 = self.input_data\n",
        "    self.A1 = self.input_data\n",
        "\n",
        "    self.Z2 = np.dot(self.A1, self.W2) + self.b2\n",
        "    self.A2 = sigmoid(self.Z2)\n",
        "\n",
        "    self.Z3 = np.dot(self.A2, self.W3) + self.b3\n",
        "    self.A3 = sigmoid(self.Z3)\n",
        "\n",
        "    return -np.sum(self.target_data * np.log(self.A3 + delta) + (1 - self.target_data)*np.log((1 - self.A3) + delta))\n",
        "\n",
        "  def loss_val(self):\n",
        "    delta = 1e-7\n",
        "\n",
        "    self.Z1 = self.input_data\n",
        "    self.A1 = self.input_data\n",
        "\n",
        "    self.Z2 = np.dot(self.A1, self.W2) + self.b2\n",
        "    self.A2 = sigmoid(self.Z2)\n",
        "\n",
        "    self.Z3 = np.dot(self.A2, self.W3) + self.b3\n",
        "    self.A3 = sigmoid(self.Z3)\n",
        "\n",
        "    return -np.sum(self.target_data * np.log(self.A3 + delta) + (1 - self.target_data)*np.log((1 - self.A3) + delta))\n",
        "\n",
        "  def train(self, input_data, target_data):\n",
        "\n",
        "    self.target_data = target_data\n",
        "    self.input_data = input_data\n",
        "\n",
        "    loss_val = self.feed_forward()\n",
        "\n",
        "    # 역전파 공식에 의한 유도이다. 이유는 다시 자세히 보도록하자.\n",
        "    loss_3 = (self.A3-self.target_data) * self.A3 * (1-self.A3)\n",
        "\n",
        "    self.W3 = self.W3 - self.learning_rate * np.dot(self.A2.T, loss_3)\n",
        "\n",
        "    self.b3 = self.b3 - self.learning_rate * loss_3\n",
        "\n",
        "    loss_2 = np.dot(loss_3, self.W3.T) * self.A2 * (1-self.A2)\n",
        "\n",
        "    self.W2 = self.W2 - self.learning_rate * np.dot(self.A1.T, loss_2)\n",
        "\n",
        "    self.b2 = self.b2 - self.learning_rate * loss_2\n",
        "\n",
        "  def predict(self, input_data):\n",
        "\n",
        "    z2 = np.dot(input_data, self.W2) + self.b2\n",
        "    a2 = sigmoid(z2)\n",
        "\n",
        "    z3 = np.dot(a2, self.W3) + self.b3\n",
        "    y = sigmoid(z3)\n",
        "\n",
        "    predicted_num = np.argmax(y)\n",
        "\n",
        "    return predicted_num\n",
        "\n",
        "  def accuracy(self, test_data):\n",
        "    matched_list = []\n",
        "    not_matched_list = []\n",
        "\n",
        "    for index in range(len(test_data)):\n",
        "\n",
        "      label = int(test_data[index, 0])\n",
        "\n",
        "      data = (test_data[index, 1:] / 255.0 * 0.99) + 0.01\n",
        "\n",
        "      predicted_num = self.predict(np.array(data, ndmin=2))\n",
        "\n",
        "\n",
        "      if label == predicted_num:\n",
        "        matched_list.append(index)\n",
        "      else:\n",
        "        not_matched_list.append(index)\n",
        "\n",
        "    print(\"Current Accuracy = \", 100*(len(matched_list)/(len(test_data))), \" %\")\n",
        "\n",
        "    return matched_list, not_matched_list\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcCTmiKgnzjf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "c12674d7-c12c-43a1-bc83-b11d3e83bd9f"
      },
      "source": [
        "input_nodes = 784\n",
        "hidden_nodes = 100\n",
        "output_nodes = 10\n",
        "learning_rate = 0.3\n",
        "epochs = 5\n",
        "\n",
        "nn = NeuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)\n",
        "\n",
        "start_time = datetime.now()\n",
        "\n",
        "for i in range(epochs):\n",
        "  for step in range(len(training_data)):\n",
        "\n",
        "    target_data = np.zeros(output_nodes) + 0.01\n",
        "    target_data[int(training_data[step, 0])] = 0.99\n",
        "\n",
        "    input_data = ((training_data[step, 1:] / 255.0) * 0.99) + 0.01\n",
        "    \n",
        "    nn.train(np.array(input_data, ndmin=2), np.array(target_data, ndmin=2))\n",
        "\n",
        "    # if step % 400 == 0:\n",
        "    #   print(\"step = \", step, \", loss_val = \", nn.loss_val())\n",
        "\n",
        "end_time = datetime.now()\n",
        "print(\"\\nelapsed time = \", end_time - start_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-5c114402ba16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.99\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# if step % 400 == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-ecd629a67279>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_data, target_data)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;31m# 역전파 공식에 의한 유도이다. 이유는 다시 자세히 보도록하자.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-ecd629a67279>\u001b[0m in \u001b[0;36mfeed_forward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZ2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZ2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQMlxEdZnzmX"
      },
      "source": [
        "(a, b) = nn.accuracy(test_data)\n",
        "#  epochs = 1 : 90.55  %\n",
        "#  epochs = 5 : 91.81  %"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9KGokYjQXgq"
      },
      "source": [
        "<h1>텐서플로우 기초</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZ1JZWDKFNft"
      },
      "source": [
        "코랩에서는 %tensorflow_version 1.x 를 이용해서 버전을 다운그레이드 할 수 있다.\n",
        "\n",
        "마찬가지로 %tensorflow_version 2.x 를 이용해서 2.x 버전을 사용할 수 있으나,\n",
        "\n",
        "현재 최신 버전이 2.x이므로 나중에 3.x 버전이 나온다면 사용하자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jr454TG_vdT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "7f1b349f-baab-49e0-de35-982a10caa9f6"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "a = tf.constant(1.0, name='a')\n",
        "b = tf.constant(2.0, name='b')\n",
        "c = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
        "\n",
        "print(a)\n",
        "print(a+b)\n",
        "print(c)\n",
        "\n",
        "sess = tf.Session()\n",
        "\n",
        "print(sess.run([a, b]))\n",
        "print(sess.run(c))\n",
        "print(sess.run([a+b]))\n",
        "print(sess.run(c+1.0))\n",
        "\n",
        "sess.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n",
            "tf.Tensor(1.0, shape=(), dtype=float32)\n",
            "tf.Tensor(3.0, shape=(), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[1. 2.]\n",
            " [3. 4.]], shape=(2, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-74b69f40e19c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'Session'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3D6quaAjnzpA"
      },
      "source": [
        "# 플레이스 홀더는 바로 값을 지정하지 않고\n",
        "# 나중에 값을 지정 받을 수 있도록하는 노드를 생성하는\n",
        "# 일종의 변수 생성 함수 느낌\n",
        "a = tf.placeholder(tf.float32)\n",
        "b = tf.placeholder(tf.float32)\n",
        "c = a+b\n",
        "\n",
        "sess = tf.Session()\n",
        "\n",
        "# run 함수의 첫번째 파라메터는 수행할 연산\n",
        "# feed_dict는 플레이스 홀더로 지정한 노드에 값을 대입시킴\n",
        "print(sess.run(c, feed_dict={a:1.0, b:3.0}))\n",
        "print(sess.run(c, feed_dict={a:[1.0,2.0], b:[3.0,4.0]}))\n",
        "\n",
        "d = 100*c\n",
        "\n",
        "print(sess.run(d, feed_dict={a:1.0, b:3.0}))\n",
        "print(sess.run(d, feed_dict={a:[1.0,2.0], b:[3.0,4.0]}))\n",
        "\n",
        "sess.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vIKaFjEnzry",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77a264b8-7356-4311-aa11-d80ccd8b8082"
      },
      "source": [
        "W1 = tf.Variable(tf.random_normal([1]))\n",
        "b1 = tf.Variable(tf.random_normal([1]))\n",
        "\n",
        "W2 = tf.Variable(tf.random_normal([1, 2]))\n",
        "b2 = tf.Variable(tf.random_normal([1, 2]))\n",
        "\n",
        "sess = tf.Session()\n",
        "# 변수 노드들을 초기화 해줌\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "for step in range(3):\n",
        "  W1 = W1 - step\n",
        "  b1 = b1 - step\n",
        "\n",
        "  W2 = W2 - step\n",
        "  b2 = b2 - step\n",
        "\n",
        "  print(\"step = \", step, \", W1 = \", sess.run(W1), \", b1 = \", sess.run(b1))\n",
        "  print(\"step = \", step, \", W2 = \", sess.run(W2), \", b2 = \", sess.run(b1))\n",
        "\n",
        "sess.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step =  0 , W1 =  [1.4349954] , b1 =  [0.03288762]\n",
            "step =  0 , W2 =  [[-0.59635735  0.09051114]] , b2 =  [0.03288762]\n",
            "step =  1 , W1 =  [0.4349954] , b1 =  [-0.96711236]\n",
            "step =  1 , W2 =  [[-1.5963573  -0.90948886]] , b2 =  [-0.96711236]\n",
            "step =  2 , W1 =  [-1.5650046] , b1 =  [-2.9671123]\n",
            "step =  2 , W2 =  [[-3.5963573 -2.909489 ]] , b2 =  [-2.9671123]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPSlxmsInzuY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "786c2b37-8335-4957-9edc-96d4670d5f38"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "loaded_data = np.array(\n",
        "[[73,\t80,\t75,\t152],\n",
        "[93,\t88,\t93,\t185],\n",
        "[89,\t91,\t90,\t180],\n",
        "[96,\t98,\t100, 196],\n",
        "[73,\t66,\t70,\t142],\n",
        "[53,\t46,\t55,\t101],\n",
        "[69,\t74,\t77,\t149],\n",
        "[47,\t56,\t60,\t115],\n",
        "[87,\t79,\t90,\t175],\n",
        "[79,\t70,\t88,\t164],\n",
        "[69,\t70,\t73,\t141],\n",
        "[70,\t65,\t74,\t141],\n",
        "[93,\t95,\t91,\t184],\n",
        "[79,\t80,\t73,\t152],\n",
        "[70,\t73,\t78,\t148],\n",
        "[93,\t89,\t96,\t192],\n",
        "[78,\t75,\t68,\t147],\n",
        "[81,\t90,\t93,\t183],\n",
        "[88,\t92,\t86,\t177],\n",
        "[78,\t83,\t77,\t159],\n",
        "[82,\t86,\t90,\t177],\n",
        "[86,\t82,\t89,\t175],\n",
        "[78,\t83,\t85,\t175],\n",
        "[76,\t83,\t71,\t149],\n",
        "[96,\t93,\t95,\t192]])\n",
        "\n",
        "x_data = loaded_data[:, 0:-1]\n",
        "t_data = loaded_data[:, [-1]]\n",
        "\n",
        "W = tf.Variable(tf.random_normal([3, 1]))\n",
        "b = tf.Variable(tf.random_normal([1]))\n",
        "\n",
        "X = tf.placeholder(tf.float32, [None, 3])\n",
        "T = tf.placeholder(tf.float32, [None, 1])\n",
        "\n",
        "y = tf.matmul(X, W) + b\n",
        "\n",
        "# 평균 제곱 오차 정의(reduce_mean은 평균을 내주는 함수)\n",
        "loss = tf.reduce_mean(tf.square(y - T))\n",
        "\n",
        "learning_rate = 1e-5\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "\n",
        "# 오차를 최소화하도록 하는 최적화 프로그램 정의\n",
        "train = optimizer.minimize(loss)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  for step in range(8001):\n",
        "    loss_val, y_val, _ = sess.run([loss, y, train], feed_dict={X:x_data, T:t_data})\n",
        "\n",
        "    if step % 400 == 0:\n",
        "      print(\"step = \", step, \", loss_val = \", loss_val)\n",
        "\n",
        "  print(\"\\nPrediction is \", sess.run(y, feed_dict={X: [ [100, 98, 81] ]}))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step =  0 , loss_val =  268882.7\n",
            "step =  400 , loss_val =  51.74098\n",
            "step =  800 , loss_val =  39.495667\n",
            "step =  1200 , loss_val =  30.651203\n",
            "step =  1600 , loss_val =  24.237522\n",
            "step =  2000 , loss_val =  19.566319\n",
            "step =  2400 , loss_val =  16.14813\n",
            "step =  2800 , loss_val =  13.6342325\n",
            "step =  3200 , loss_val =  11.775485\n",
            "step =  3600 , loss_val =  10.393384\n",
            "step =  4000 , loss_val =  9.359696\n",
            "step =  4400 , loss_val =  8.581998\n",
            "step =  4800 , loss_val =  7.9933233\n",
            "step =  5200 , loss_val =  7.5450106\n",
            "step =  5600 , loss_val =  7.2015376\n",
            "step =  6000 , loss_val =  6.9368553\n",
            "step =  6400 , loss_val =  6.731713\n",
            "step =  6800 , loss_val =  6.5718737\n",
            "step =  7200 , loss_val =  6.44666\n",
            "step =  7600 , loss_val =  6.3481236\n",
            "step =  8000 , loss_val =  6.2702236\n",
            "\n",
            "Prediction is  [[180.85518]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFYq7B74nzww",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75a01851-6b8a-4b56-a684-e692b2a8b6ee"
      },
      "source": [
        "loaded_data = np.loadtxt(\"/content/drive/MyDrive/딥러닝 강의 자료/neowizard-master/MachineLearning/diabetes.csv\", delimiter=',')\n",
        "\n",
        "x_data = loaded_data[:,0:-1]\n",
        "t_data = loaded_data[:,[-1]]\n",
        "\n",
        "print(\"loaded_data = \", loaded_data.shape)\n",
        "print(\"x_data = \", x_data.shape, \", t_data = \", t_data.shape)\n",
        "\n",
        "X = tf.placeholder(tf.float32, [None, 8])\n",
        "T = tf.placeholder(tf.float32, [None, 1])\n",
        "\n",
        "W = tf.Variable(tf.random_normal([8, 1]))\n",
        "b = tf.Variable(tf.random_normal([1]))\n",
        "\n",
        "z = tf.matmul(X, W) + b\n",
        "\n",
        "y = tf.sigmoid(z)\n",
        "\n",
        "loss = -tf.reduce_mean(T*tf.log(y) + (1-T)*tf.log(1-y))\n",
        "\n",
        "learning_rate = 0.01\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "\n",
        "train = optimizer.minimize(loss)\n",
        "\n",
        "# cast는 첫번째 파라메터가 True면 1을, False면 0으로 변환해주는 함수\n",
        "predicted = tf.cast(y > 0.5, dtype=tf.float32)\n",
        "\n",
        "# 예측값과 실제 데이터를 비교해 0과 1로 변환 후 \n",
        "# 평균을 내서 정확도를 검증하는 부분\n",
        "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, T), dtype=tf.float32))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "\n",
        "  for step in range(20001):\n",
        "\n",
        "    loss_val, _ = sess.run([loss, train], feed_dict={X:x_data, T:t_data})\n",
        "\n",
        "    if step % 500 == 0:\n",
        "      print(\"step = \", step, \", loss_val = \", loss_val)\n",
        "\n",
        "  y_val, predicted_val, accuracy_val = sess.run([y, predicted, accuracy], feed_dict={X: x_data, T: t_data})\\\n",
        "  \n",
        "  print(\"\\ny_val.shape = \", y_val.shape, \", predicted_val = \", predicted_val.shape)\n",
        "  print(\"\\nAccuracy = \", accuracy_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loaded_data =  (759, 9)\n",
            "x_data =  (759, 8) , t_data =  (759, 1)\n",
            "step =  0 , loss_val =  1.3911625\n",
            "step =  500 , loss_val =  0.7756136\n",
            "step =  1000 , loss_val =  0.69652444\n",
            "step =  1500 , loss_val =  0.64218885\n",
            "step =  2000 , loss_val =  0.60221344\n",
            "step =  2500 , loss_val =  0.57289034\n",
            "step =  3000 , loss_val =  0.5513024\n",
            "step =  3500 , loss_val =  0.5352739\n",
            "step =  4000 , loss_val =  0.5232385\n",
            "step =  4500 , loss_val =  0.51408476\n",
            "step =  5000 , loss_val =  0.50702864\n",
            "step =  5500 , loss_val =  0.5015158\n",
            "step =  6000 , loss_val =  0.49715182\n",
            "step =  6500 , loss_val =  0.4936536\n",
            "step =  7000 , loss_val =  0.4908158\n",
            "step =  7500 , loss_val =  0.48848805\n",
            "step =  8000 , loss_val =  0.48655868\n",
            "step =  8500 , loss_val =  0.48494393\n",
            "step =  9000 , loss_val =  0.48358035\n",
            "step =  9500 , loss_val =  0.48241913\n",
            "step =  10000 , loss_val =  0.4814225\n",
            "step =  10500 , loss_val =  0.4805612\n",
            "step =  11000 , loss_val =  0.47981152\n",
            "step =  11500 , loss_val =  0.47915512\n",
            "step =  12000 , loss_val =  0.47857693\n",
            "step =  12500 , loss_val =  0.4780649\n",
            "step =  13000 , loss_val =  0.4776092\n",
            "step =  13500 , loss_val =  0.4772015\n",
            "step =  14000 , loss_val =  0.47683528\n",
            "step =  14500 , loss_val =  0.47650492\n",
            "step =  15000 , loss_val =  0.47620562\n",
            "step =  15500 , loss_val =  0.4759336\n",
            "step =  16000 , loss_val =  0.47568542\n",
            "step =  16500 , loss_val =  0.47545815\n",
            "step =  17000 , loss_val =  0.47524953\n",
            "step =  17500 , loss_val =  0.47505748\n",
            "step =  18000 , loss_val =  0.4748801\n",
            "step =  18500 , loss_val =  0.4747158\n",
            "step =  19000 , loss_val =  0.4745633\n",
            "step =  19500 , loss_val =  0.47442147\n",
            "step =  20000 , loss_val =  0.47428912\n",
            "\n",
            "y_val.shape =  (759, 1) , predicted_val =  (759, 1)\n",
            "\n",
            "Accuracy =  0.76943344\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBlmrGD9nzzj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a580bb0f-fc3e-47c4-f22d-7c1f09e17285"
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)\n",
        "\n",
        "print(\"\\n\", mnist.train.num_examples, mnist.test.num_examples, mnist.validation.num_examples)\n",
        "\n",
        "print(\"\\ntrain image shape = \", np.shape(mnist.train.images))\n",
        "print(\"train label shape = \", np.shape(mnist.train.labels))\n",
        "print(\"test image shape = \", np.shape(mnist.test.images))\n",
        "print(\"test label shape = \", np.shape(mnist.test.labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-7-aacdf67322bc>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "\n",
            " 55000 10000 5000\n",
            "\n",
            "train image shape =  (55000, 784)\n",
            "train label shape =  (55000, 10)\n",
            "test image shape =  (10000, 784)\n",
            "test label shape =  (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxza_TOHnz21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1818b247-54b6-48ff-ea20-286a97232d8f"
      },
      "source": [
        "learning_rate = 0.1\n",
        "epochs = 100\n",
        "batch_size = 100\n",
        "\n",
        "input_nodes = 784\n",
        "hidden_nodes = 100\n",
        "output_nodes = 10\n",
        "\n",
        "X = tf.placeholder(tf.float32, [None, input_nodes])\n",
        "T = tf.placeholder(tf.float32, [None, output_nodes])\n",
        "\n",
        "W2 = tf.Variable(tf.random_normal([input_nodes, hidden_nodes]))\n",
        "b2 = tf.Variable(tf.random_normal([hidden_nodes]))\n",
        "\n",
        "W3 = tf.Variable(tf.random_normal([hidden_nodes, output_nodes]))\n",
        "b3 = tf.Variable(tf.random_normal([output_nodes]))\n",
        "\n",
        "Z2 = tf.matmul(X, W2) + b2\n",
        "A2 = tf.nn.relu(Z2)\n",
        "\n",
        "Z3 = logits = tf.matmul(A2, W3) + b3\n",
        "\n",
        "y = A3 = tf.nn.softmax(Z3)\n",
        "\n",
        "# loss = tf.reduce_mean(-(T*tf.log(softmax(Z3)) + (1-T)*tf.log(1-softmax(Z3))))\n",
        "# 위의 식과 아래의 식은 같다.\n",
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=Z3, labels=T))\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "\n",
        "train = optimizer.minimize(loss)\n",
        "\n",
        "predicted_val = tf.equal(tf.argmax(A3, 1), tf.argmax(T, 1))\n",
        "\n",
        "accuracy = tf.reduce_mean(tf.cast(predicted_val, dtype=tf.float32))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  \n",
        "  for i in range(epochs):\n",
        "\n",
        "    total_batch = int(mnist.train.num_examples / batch_size)\n",
        "\n",
        "    for step in range(total_batch):\n",
        "      # batch_size 만큼의 데이터를 임의로 뽑아서\n",
        "      # batch_x_data, batch_t_data에 각각 대입해줌\n",
        "      batch_x_data, batch_t_data = mnist.train.next_batch(batch_size)\n",
        "\n",
        "      loss_val, _ = sess.run([loss, train], feed_dict={X:batch_x_data, T: batch_t_data})\n",
        "\n",
        "      if step % 100 == 0:\n",
        "        print(\"step = \", step, \", loss_val = \", loss_val)\n",
        "\n",
        "  test_x_data = mnist.test.images\n",
        "  test_t_data = mnist.test.labels\n",
        "\n",
        "  accuracy_val = sess.run(accuracy, feed_dict={X:test_x_data, T: test_t_data})\n",
        "  predicted = sess.run(predicted_val, feed_dict={X:test_x_data, T: test_t_data})\n",
        "\n",
        "  print(\"\\npredicted = \", predicted)\n",
        "  print(\"\\nAccuracy = \", accuracy_val)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step =  0 , loss_val =  133.10918\n",
            "step =  100 , loss_val =  3.5327537\n",
            "step =  200 , loss_val =  4.977753\n",
            "step =  300 , loss_val =  3.350122\n",
            "step =  400 , loss_val =  2.239846\n",
            "step =  500 , loss_val =  2.2090857\n",
            "step =  0 , loss_val =  1.2507958\n",
            "step =  100 , loss_val =  1.2794678\n",
            "step =  200 , loss_val =  0.44986352\n",
            "step =  300 , loss_val =  1.5978242\n",
            "step =  400 , loss_val =  1.0930991\n",
            "step =  500 , loss_val =  1.4487315\n",
            "step =  0 , loss_val =  0.67526007\n",
            "step =  100 , loss_val =  1.1012994\n",
            "step =  200 , loss_val =  0.4104523\n",
            "step =  300 , loss_val =  1.1344705\n",
            "step =  400 , loss_val =  0.6048766\n",
            "step =  500 , loss_val =  0.62077594\n",
            "step =  0 , loss_val =  0.50286895\n",
            "step =  100 , loss_val =  0.8208871\n",
            "step =  200 , loss_val =  0.86970305\n",
            "step =  300 , loss_val =  0.346918\n",
            "step =  400 , loss_val =  0.3797512\n",
            "step =  500 , loss_val =  0.2309642\n",
            "step =  0 , loss_val =  0.25129312\n",
            "step =  100 , loss_val =  0.2534806\n",
            "step =  200 , loss_val =  0.675978\n",
            "step =  300 , loss_val =  0.27918315\n",
            "step =  400 , loss_val =  0.8708437\n",
            "step =  500 , loss_val =  0.61760545\n",
            "step =  0 , loss_val =  0.37038022\n",
            "step =  100 , loss_val =  0.2482332\n",
            "step =  200 , loss_val =  0.14380008\n",
            "step =  300 , loss_val =  0.21081619\n",
            "step =  400 , loss_val =  0.44971067\n",
            "step =  500 , loss_val =  0.36106813\n",
            "step =  0 , loss_val =  0.22555332\n",
            "step =  100 , loss_val =  0.21025442\n",
            "step =  200 , loss_val =  0.6120147\n",
            "step =  300 , loss_val =  0.22527191\n",
            "step =  400 , loss_val =  0.30914468\n",
            "step =  500 , loss_val =  0.36181104\n",
            "step =  0 , loss_val =  0.19289799\n",
            "step =  100 , loss_val =  0.16837853\n",
            "step =  200 , loss_val =  0.44804615\n",
            "step =  300 , loss_val =  0.4348745\n",
            "step =  400 , loss_val =  0.38321364\n",
            "step =  500 , loss_val =  0.15364157\n",
            "step =  0 , loss_val =  0.47158346\n",
            "step =  100 , loss_val =  0.29166913\n",
            "step =  200 , loss_val =  0.43818635\n",
            "step =  300 , loss_val =  0.41863236\n",
            "step =  400 , loss_val =  0.3075629\n",
            "step =  500 , loss_val =  0.4257249\n",
            "step =  0 , loss_val =  0.325741\n",
            "step =  100 , loss_val =  0.37831226\n",
            "step =  200 , loss_val =  0.32293773\n",
            "step =  300 , loss_val =  0.4776344\n",
            "step =  400 , loss_val =  0.19900055\n",
            "step =  500 , loss_val =  0.13832146\n",
            "step =  0 , loss_val =  0.30263013\n",
            "step =  100 , loss_val =  0.2373698\n",
            "step =  200 , loss_val =  0.3225617\n",
            "step =  300 , loss_val =  0.22025213\n",
            "step =  400 , loss_val =  0.285002\n",
            "step =  500 , loss_val =  0.24307728\n",
            "step =  0 , loss_val =  0.56991315\n",
            "step =  100 , loss_val =  0.5123542\n",
            "step =  200 , loss_val =  0.29919717\n",
            "step =  300 , loss_val =  0.29574192\n",
            "step =  400 , loss_val =  0.22885698\n",
            "step =  500 , loss_val =  0.38446105\n",
            "step =  0 , loss_val =  0.18629402\n",
            "step =  100 , loss_val =  0.14813921\n",
            "step =  200 , loss_val =  0.2552\n",
            "step =  300 , loss_val =  0.30178535\n",
            "step =  400 , loss_val =  0.55079454\n",
            "step =  500 , loss_val =  0.30681953\n",
            "step =  0 , loss_val =  0.29191858\n",
            "step =  100 , loss_val =  0.32193008\n",
            "step =  200 , loss_val =  0.41422957\n",
            "step =  300 , loss_val =  0.19263138\n",
            "step =  400 , loss_val =  0.33331746\n",
            "step =  500 , loss_val =  0.24607173\n",
            "step =  0 , loss_val =  0.20891957\n",
            "step =  100 , loss_val =  0.19279128\n",
            "step =  200 , loss_val =  0.23707493\n",
            "step =  300 , loss_val =  0.2606105\n",
            "step =  400 , loss_val =  0.40371627\n",
            "step =  500 , loss_val =  0.19683856\n",
            "step =  0 , loss_val =  0.43783042\n",
            "step =  100 , loss_val =  0.1535913\n",
            "step =  200 , loss_val =  0.5046892\n",
            "step =  300 , loss_val =  0.2371523\n",
            "step =  400 , loss_val =  0.17701598\n",
            "step =  500 , loss_val =  0.18240021\n",
            "step =  0 , loss_val =  0.15968075\n",
            "step =  100 , loss_val =  0.39842933\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-1b6379f829e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m       \u001b[0mbatch_x_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_t_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m       \u001b[0mloss_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_x_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_t_data\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1346\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m   1350\u001b[0m                                       target_list, run_metadata)\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1386\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m   \u001b[0;31m# The threshold to run garbage collection to delete dead tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nSW2eFmcBzC"
      },
      "source": [
        "<h1>CNN</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7lSS3WFnz5F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "0370eff8-b86c-4468-8af3-e28a8fceb93c"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)\n",
        "\n",
        "print(\"\\n\", mnist.train.num_examples, mnist.test.num_examples, mnist.validation.num_examples)\n",
        "\n",
        "print(\"\\ntrain image shape = \", np.shape(mnist.train.images))\n",
        "print(\"train label shape = \", np.shape(mnist.train.labels))\n",
        "print(\"test image shape = \", np.shape(mnist.test.images))\n",
        "print(\"test label shape = \", np.shape(mnist.test.labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-4b815e8f209d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtutorials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmnist\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.examples'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06OO5iYwnz-O"
      },
      "source": [
        "learning_rate = 0.001\n",
        "epochs = 30\n",
        "batch_size = 100\n",
        "\n",
        "X = tf.placeholder(tf.float32, [None, 784])\n",
        "\n",
        "T = tf.placeholder(tf.float32, [None, 10])\n",
        "\n",
        "A1 = X_img = tf.reshape(X, [-1, 28, 28, 1])\n",
        "\n",
        "F2 = tf.Variable(tf.random_normal([3,3,1,32], stddev=0.01))\n",
        "b2 = tf.Variable(tf.constant(0.1, shape=[32]))\n",
        "\n",
        "C2 = tf.nn.conv2d(A1, F2, strides=[1,1,1,1], padding=\"SAME\")\n",
        "\n",
        "Z2 = tf.nn.relu(C2 + b2)\n",
        "\n",
        "A2 = P2 = tf.nn.max_pool(Z2, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
        "\n",
        "F3 = tf.Variable(tf.random_normal([3,3,32,64], stddev=0.01))\n",
        "b3 = tf.Variable(tf.constant(0.1, shape=[64]))\n",
        "\n",
        "C3 = tf.nn.conv2d(A2, F3, strides=[1,1,1,1], padding=\"SAME\")\n",
        "\n",
        "Z3 = tf.nn.relu(C3 + b3)\n",
        "\n",
        "A3 = P3 = tf.nn.max_pool(Z3, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
        "\n",
        "F4 = tf.Variable(tf.random_normal([3,3,64,128], stddev=0.01))\n",
        "b4 = tf.Variable(tf.constant(0.1, shape=[128]))\n",
        "\n",
        "C4 = tf.nn.conv2d(A3, F4, strides=[1,1,1,1], padding=\"SAME\")\n",
        "\n",
        "Z4 = tf.nn.relu(C4 + b4)\n",
        "\n",
        "A4 = P4 = tf.nn.max_pool(Z4, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
        "\n",
        "A4_flat = P4_flat = tf.reshape(A4, [-1, 128*4*4])\n",
        "\n",
        "W5 = tf.Variable(tf.random_normal([128*4*4, 10], stddev=0.01))\n",
        "b5 = tf.Variable(tf.random_normal([10]))\n",
        "\n",
        "Z5 = logits = tf.matmul(A4_flat, W5) + b5\n",
        "\n",
        "y = A5 = tf.nn.softmax(Z5)\n",
        "\n",
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=Z5, labels=T))\n",
        "\n",
        "train = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
        "\n",
        "predicted_val = tf.equal(tf.argmax(A5, 1), tf.argmax(T, 1))\n",
        "\n",
        "accuracy = tf.reduce_mean(tf.cast(predicted_val, dtype=tf.float32))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "\n",
        "  start_time = datetime.now()\n",
        "\n",
        "  for i in range(epochs):\n",
        "\n",
        "    total_batch = int(mnist.train.num_examples / batch_size)\n",
        "\n",
        "    for step in range(total_batch):\n",
        "\n",
        "      batch_x_data, batch_t_data = mnist.train.next_batch(batch_size)\n",
        "\n",
        "      loss_val, _ = sess.run([loss, train], feed_dict={X: batch_x_data, T: batch_t_data})\n",
        "\n",
        "      if step % 100 == 0:\n",
        "        print(\"epochs = \", i, \", step = \", step, \", loss_val\", loss_val)\n",
        "\n",
        "  end_time = datetime.now()\n",
        "\n",
        "  print(\"\\nelapsed time = \", end_time - start_time)\n",
        "\n",
        "  test_x_data = mnist.test.images\n",
        "  test_t_data = mnist.test.labels\n",
        "\n",
        "  accuracy_val = sess.run(accuracy, feed_dict={X: test_x_data, T: test_t_data})\n",
        "\n",
        "  print(\"\\nAccuracy = \", accuracy_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06QIsRlFjZjQ"
      },
      "source": [
        "<h1>RNN</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_K-Ep6QNgBdA",
        "outputId": "6d6f1f18-2c96-4b1f-9ecd-cddc283ce5a8"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVko7updhUIk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a91abdc1-1795-4c5e-bd7e-c6d5cae6746d"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "idx2char = [\"g\", \"o\", \"h\", \"m\", \"e\"]\n",
        "\n",
        "x_data = [[0,1,2,1,3]]\n",
        "\n",
        "x_one_hot = [[[1,0,0,0],\n",
        "              [0,1,0,0],\n",
        "              [0,0,1,0],\n",
        "              [0,1,0,0],\n",
        "              [0,0,0,1]]]\n",
        "\n",
        "t_data = [[1,2,1,3,4]]\n",
        "\n",
        "num_classes = 5\n",
        "input_dim = 4\n",
        "hidden_size = 5\n",
        "batch_size = 1\n",
        "sequence_length = 5\n",
        "learning_rate = 0.1\n",
        "\n",
        "X = tf.placeholder(tf.float32, [None, sequence_length, input_dim])\n",
        "T = tf.placeholder(tf.int32, [None, sequence_length])\n",
        "\n",
        "cell = tf.contrib.rnn.BasicRNNCell(num_units=hidden_size)\n",
        "\n",
        "initial_state = cell.zero_state(batch_size, tf.float32)  \n",
        "\n",
        "outputs, _states = tf.nn.dynamic_rnn(cell, X, initial_state=initial_state, dtype=tf.float32)\n",
        "\n",
        "weights = tf.ones([batch_size, sequence_length])\n",
        "\n",
        "seq_loss = tf.contrib.seq2seq.sequence_loss(logits=outputs, targets=T, weights=weights)\n",
        "\n",
        "loss = tf.reduce_mean(seq_loss)\n",
        "\n",
        "train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
        "\n",
        "y = prediction = tf.argmax(outputs, axis=2)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  \n",
        "  sess.run(tf.global_variables_initializer())\n",
        "\n",
        "  for step in range(2001):\n",
        "\n",
        "    loss_val, _ = sess.run([loss, train], feed_dict={X: x_one_hot, T: t_data})\n",
        "\n",
        "    result = sess.run(y, feed_dict={X: x_one_hot})\n",
        "\n",
        "    if step % 400 == 0:\n",
        "      print(\"step = \", step, \", loss = \", loss_val, \", prediction = \", result, \", target = \", t_data)\n",
        "\n",
        "      result_str = [idx2char[c] for c in np.squeeze(result)]\n",
        "\n",
        "      print(\"Prediction = \", ''.join(result_str))\n",
        "      print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-2-ba608e4fc272>:26: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-2-ba608e4fc272>:30: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/rnn_cell_impl.py:456: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/rnn_cell_impl.py:460: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "step =  0 , loss =  1.6024787 , prediction =  [[1 0 3 0 4]] , target =  [[1, 2, 1, 3, 4]]\n",
            "Prediction =  ogmge\n",
            "\n",
            "step =  400 , loss =  0.453442 , prediction =  [[1 2 1 3 4]] , target =  [[1, 2, 1, 3, 4]]\n",
            "Prediction =  ohome\n",
            "\n",
            "step =  800 , loss =  0.44725204 , prediction =  [[1 2 1 3 4]] , target =  [[1, 2, 1, 3, 4]]\n",
            "Prediction =  ohome\n",
            "\n",
            "step =  1200 , loss =  0.44453636 , prediction =  [[1 2 1 3 4]] , target =  [[1, 2, 1, 3, 4]]\n",
            "Prediction =  ohome\n",
            "\n",
            "step =  1600 , loss =  0.44298452 , prediction =  [[1 2 1 3 4]] , target =  [[1, 2, 1, 3, 4]]\n",
            "Prediction =  ohome\n",
            "\n",
            "step =  2000 , loss =  0.9219166 , prediction =  [[1 3 1 3 4]] , target =  [[1, 2, 1, 3, 4]]\n",
            "Prediction =  omome\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IBME7hHAdgC"
      },
      "source": [
        "<h1>Transfer Learning</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmkyA_KaGJiY"
      },
      "source": [
        "미리 학습되어있는 모델(pretraining model)에 우리의 데이터를 추가적으로 학습해서 가중치와 바이어스 등의 값을 조금 조정한다(fine tuning). 모델을 처음부터 구축할 경우 생기는 매우 긴 학급시간을 거치지 않아도 금방 고해상도의 사진을 학습할 수 있다. Google Inception model과 MS ResNet model등이 오픈 소스로 배포되고 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWvu36jaE2zx"
      },
      "source": [
        "아나콘다 다운로드해서 다시해봐야 할듯함. 구글 드라이드로 되는지 확인이 안됨. 또한 하모니카 os에서 flower_photos.zip 파일을 압축풀기하면 오류가 발생함. 윈도우에서 시도해볼것.\n",
        "\n",
        "드라이브를 이용해서 시도해볼 경우 아래의 경로를 추가하여 명령어들의 경로를 수정해줄것.\n",
        "(/content/drive/MyDrive/딥러닝 강의 자료/neowizard-master/MachineLearning)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xj5kNJizDakm"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkqAlrfEn0EB"
      },
      "source": [
        "# Training Data들을 재학습시킴(파인 튜닝). 파인 튜닝으로 학습된 가중치와 바이어스등의 학습결과는 /tmp에 저장됨.\n",
        "!python  ./retrain.py --image_dir=./flower_photos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RoCIkMmAhHt"
      },
      "source": [
        "# 학습된 내용을 바탕으로 이미지 분류를 수행 (해바라기 사진 분류 test)\n",
        "!python ./label_image.py --graph=/tmp/output_graph.pb --labels=/tmp/output_labels.txt --input_layer=Placeholder --output_layer=final_result --image=./sunflower5.jpg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXgtq9g_n0Gd"
      },
      "source": [
        "# 학습된 내용을 바탕으로 이미지 분류를 수행 (장미 사진 분류 test)\n",
        "!python ./label_image.py --graph=/tmp/output_graph.pb --labels=/tmp/output_labels.txt --input_layer=Placeholder --output_layer=final_result --image=./rose2.jpg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpXJvKLHn0I-"
      },
      "source": [
        "# 학습된 내용을 바탕으로 이미지 분류를 수행 (튤립 사진 분류 test)\n",
        "!python ./label_image.py --graph=/tmp/output_graph.pb --labels=/tmp/output_labels.txt --input_layer=Placeholder --output_layer=final_result --image=./tulip5.jpg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74Ja-V59KDvw"
      },
      "source": [
        "<h1>Google Colab 사용법</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_I9n-m-KIDF"
      },
      "source": [
        "일반적인 리눅스 명령어 사용가능"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGrsPQ40n0LG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "399d922b-8803-4f36-d538-33ef8997df78"
      },
      "source": [
        "!pwd\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAXUQz2sMTed",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "outputId": "846e48a4-d2bf-4538-cfc9-63ff26f53ac7"
      },
      "source": [
        "# 로컬 PC의 파일 업로드 방법\n",
        "from google.colab import files\n",
        "\n",
        "uploaded  = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print(\"User uploaded file '{name}'  with length {length} bytes\".format(name = fn, lenth = len(uploaded[fn])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3095fa8f-98a3-4d36-86f0-df022b7a48bb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3095fa8f-98a3-4d36-86f0-df022b7a48bb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-d74e44e2e5b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0muploaded\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muploaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m   result = _output.eval_js(\n\u001b[1;32m     63\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[0;32m---> 64\u001b[0;31m           input_id=input_id, output_id=output_id))\n\u001b[0m\u001b[1;32m     65\u001b[0m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHqojd3sMTg7"
      },
      "source": [
        "# 코랩에 있는 파일을 로컬 PC로 다운로드 하는 방법\n",
        "files.download(\"파일이름.확장자\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ybSBtgOMTjR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNs5vVDOMTlG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxloSQruMTnc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJT3qHWVMTph"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlpiOeeODrgg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ux9JKmCBDrkJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}